{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a917f-74e4-46a1-95f0-54e9a551b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ebda2-dd82-4814-94a7-b679f6165a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5360a-2fde-4bd1-818b-7724765d7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040025ef-20ab-4554-abd6-90254f9e3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa16ed-93c1-456f-9b39-725279e3d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.n_epochs = 200\n",
    "        self.batch_size = 32\n",
    "        self.lr = 0.002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.n_cpu = 8\n",
    "        self.latent_dim  = 100\n",
    "        self.n_classes = 4\n",
    "        self.img_size = 128\n",
    "        self.channels = 3\n",
    "        self.sample_interval = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519edd39-d5e7-458e-980e-5c2cf62b0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498996f-3e56-4cbd-81d3-3f7db3617ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "#cuda = False\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.latent_dim)\n",
    "\n",
    "        self.init_size = opt.img_size // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, opt.n_classes), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec0e2e-4ea8-4f08-bb70-87110990f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c10610-37af-420d-b645-4154cf0d7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from PIL import Image\n",
    "\n",
    "size = (512, 512)\n",
    "\n",
    "p = r\"C:\\Users\\原神\\Downloads\\cats\"+\"\\\\\"\n",
    "name = \"cats\"\n",
    "\n",
    "for infile in os.listdir(p+\"val\\\\\"+name):\n",
    "        im = Image.open(p+\"val\\\\\"+name+\"\\\\\"+infile)\n",
    "        im = im.resize(size)\n",
    "        im = im.convert(\"RGB\")\n",
    "        im.save(p+\"val\\\\\"+name+\"\\\\\"+infile, \"JPEG\")\n",
    "\n",
    "for infile in os.listdir(p+\"train\\\\\"+name):\n",
    "        im = Image.open(p+\"train\\\\\"+name+\"\\\\\"+infile)\n",
    "        im = im.resize(size)\n",
    "        im = im.convert(\"RGB\")\n",
    "        im.save(p+\"train\\\\\"+name+\"\\\\\"+infile, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46210b9d-2038-4268-b976-07aba98f8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=p,\n",
    "                               transform = transforms.Compose(\n",
    "                                   [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afae7a-29de-434e-9a0b-ce06a3482505",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a88fb-679f-4561-b6b1-a4c7fc68284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40b566-94a4-450e-85ad-7cd1d3aa885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.lr = 0.0002\n",
    "opt.n_epochs = 5000\n",
    "opt.sample_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e48b4-9aa8-4a38-8c04-2dfbc56fc791",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ab6ad-43b0-4ccd-b5ca-b40c7521646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3428dea-b820-4d93-9325-5831aeda0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity, pred_label = discriminator(gen_imgs)\n",
    "        g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        real_pred, real_aux = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # Loss for fake images\n",
    "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item()),end=\"\"\n",
    "        )\n",
    "        batches_done += 1\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "                sample_image(n_row=opt.n_classes, batches_done=batches_done)\n",
    "\n",
    "        #gc.collect()\n",
    "        #torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f49e05-ca55-4673-ad07-9ab2b507963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image(n_row=opt.n_classes, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8ae25-0e17-4fa1-81d0-3c8598ca2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = r\"C:\\Users\\TEST\\generator_cat128rgb.pth\"\n",
    "dp = r\"C:\\Users\\TEST\\discriminator_cat128rgb.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255c631-0aaa-4ba2-8cd9-28e74adeb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ea98a-33ec-4c39-8bfd-942f24deccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(discriminator.state_dict(), dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06c9ce-2588-4fba-bb6a-4d83305652bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a random image\n",
    "sample_image(n_row=1, batches_done=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ab4e5-7fb1-450d-a4b8-c62a4b544937",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_state_dict(torch.load(dp, weights_only=True))\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3d1e2-4904-4fe5-af38-c654ab7196b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load(gp, weights_only=True))\n",
    "generator.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
