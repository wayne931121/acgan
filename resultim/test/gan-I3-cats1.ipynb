{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57a917f-74e4-46a1-95f0-54e9a551b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6ebda2-dd82-4814-94a7-b679f6165a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc5360a-2fde-4bd1-818b-7724765d7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfa16ed-93c1-456f-9b39-725279e3d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.n_epochs = 200\n",
    "        self.batch_size = 54 # 128*128 img_size*img_size\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.n_cpu = 8\n",
    "        self.latent_dim  = 62\n",
    "    #    self.n_classes = 10\n",
    "        self.img_size = 128\n",
    "        self.channels = 3\n",
    "        self.sample_interval = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519edd39-d5e7-458e-980e-5c2cf62b0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0498996f-3e56-4cbd-81d3-3f7db3617ec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity\n",
    "\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01785861-4f7c-4a70-866c-e73d0f8f4d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/error-expected-more-than-1-value-per-channel-when-training/26274\n",
    "test = generator.eval()\n",
    "test = discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c10610-37af-420d-b645-4154cf0d7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"C:\\Users\\原神\\Downloads\\cats\"+\"\\\\\"\n",
    "name = \"cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0409288b-d432-4420-9a99-92fa1a95522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "# from PIL import Image\n",
    "\n",
    "# size = (128,128)\n",
    "\n",
    "# for infile in os.listdir(p+\"val\\\\\"+name):\n",
    "#         im = Image.open(p+\"val\\\\\"+name+\"\\\\\"+infile)\n",
    "#         im = im.resize(size)\n",
    "#         im = im.convert(\"RGB\")\n",
    "#         os.remove(p+\"val\\\\\"+name+\"\\\\\"+infile)\n",
    "#         im.save(p+\"val\\\\\"+name+\"\\\\\"+infile.replace(\"png\",\"jpg\"), \"JPEG\")\n",
    "\n",
    "# for infile in os.listdir(p+\"train\\\\\"+name):\n",
    "#         im = Image.open(p+\"train\\\\\"+name+\"\\\\\"+infile)\n",
    "#         im = im.resize(size)\n",
    "#         im = im.convert(\"RGB\")\n",
    "#         os.remove(p+\"train\\\\\"+name+\"\\\\\"+infile)\n",
    "#         im.save(p+\"train\\\\\"+name+\"\\\\\"+infile.replace(\"png\",\"jpg\"), \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46210b9d-2038-4268-b976-07aba98f8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=p,\n",
    "                               transform = transforms.Compose(\n",
    "                                   [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32afae7a-29de-434e-9a0b-ce06a3482505",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed40b566-94a4-450e-85ad-7cd1d3aa885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df6e9cc-f390-4843-9a58-e56a09e2622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.n_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed710e1-855e-4a69-9a2a-f1794c6d6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer_G.param_groups[0]['lr'] = 1e-4\n",
    "# optimizer_D.param_groups[0]['lr'] = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf2c2cc-ca6e-448f-a42b-b8078e88ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.sample_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33d96abc-e65c-4632-b6e1-bb0932a8546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aef1c5f8-9660-4679-9387-befbdd453749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\原神\\AppData\\Local\\Temp\\ipykernel_2884\\1089692113.py:5: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\tensor\\python_tensor.cpp:80.)\n",
      "  valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/5000] [Batch 0/1] [D loss: 0.690324] [G loss: 0.693300]\n",
      "[Epoch 1/5000] [Batch 0/1] [D loss: 0.599729] [G loss: 0.698724]\n",
      "[Epoch 2/5000] [Batch 0/1] [D loss: 0.358436] [G loss: 0.709128]\n",
      "[Epoch 3/5000] [Batch 0/1] [D loss: 0.337673] [G loss: 0.723888]\n",
      "[Epoch 4/5000] [Batch 0/1] [D loss: 0.327015] [G loss: 0.740180]\n",
      "[Epoch 5/5000] [Batch 0/1] [D loss: 0.319749] [G loss: 0.754252]\n",
      "[Epoch 6/5000] [Batch 0/1] [D loss: 0.309037] [G loss: 0.778558]\n",
      "[Epoch 7/5000] [Batch 0/1] [D loss: 0.303055] [G loss: 0.795050]\n",
      "[Epoch 8/5000] [Batch 0/1] [D loss: 0.281394] [G loss: 0.860987]\n",
      "[Epoch 9/5000] [Batch 0/1] [D loss: 0.258833] [G loss: 0.979224]\n",
      "[Epoch 10/5000] [Batch 0/1] [D loss: 0.278586] [G loss: 0.892772]\n",
      "[Epoch 11/5000] [Batch 0/1] [D loss: 0.217008] [G loss: 1.108344]\n",
      "[Epoch 12/5000] [Batch 0/1] [D loss: 0.189435] [G loss: 1.288124]\n",
      "[Epoch 13/5000] [Batch 0/1] [D loss: 0.196934] [G loss: 1.152338]\n",
      "[Epoch 14/5000] [Batch 0/1] [D loss: 0.193045] [G loss: 1.194804]\n",
      "[Epoch 15/5000] [Batch 0/1] [D loss: 0.216201] [G loss: 1.072815]\n",
      "[Epoch 16/5000] [Batch 0/1] [D loss: 0.242492] [G loss: 0.987190]\n",
      "[Epoch 17/5000] [Batch 0/1] [D loss: 0.298983] [G loss: 0.823156]\n",
      "[Epoch 18/5000] [Batch 0/1] [D loss: 0.304967] [G loss: 0.801294]\n",
      "[Epoch 19/5000] [Batch 0/1] [D loss: 0.380929] [G loss: 0.637576]\n",
      "[Epoch 20/5000] [Batch 0/1] [D loss: 0.377845] [G loss: 0.639813]\n",
      "[Epoch 21/5000] [Batch 0/1] [D loss: 0.360668] [G loss: 0.670162]\n",
      "[Epoch 22/5000] [Batch 0/1] [D loss: 0.346182] [G loss: 0.697394]\n",
      "[Epoch 23/5000] [Batch 0/1] [D loss: 0.339029] [G loss: 0.711944]\n",
      "[Epoch 24/5000] [Batch 0/1] [D loss: 0.320735] [G loss: 0.750327]\n",
      "[Epoch 25/5000] [Batch 0/1] [D loss: 0.306376] [G loss: 0.783688]\n",
      "[Epoch 26/5000] [Batch 0/1] [D loss: 0.294311] [G loss: 0.813808]\n",
      "[Epoch 27/5000] [Batch 0/1] [D loss: 0.289321] [G loss: 0.832404]\n",
      "[Epoch 28/5000] [Batch 0/1] [D loss: 0.276465] [G loss: 0.862470]\n",
      "[Epoch 29/5000] [Batch 0/1] [D loss: 0.246362] [G loss: 0.958692]\n",
      "[Epoch 30/5000] [Batch 0/1] [D loss: 0.176147] [G loss: 1.226078]\n",
      "[Epoch 31/5000] [Batch 0/1] [D loss: 0.104664] [G loss: 1.681620]\n",
      "[Epoch 32/5000] [Batch 0/1] [D loss: 0.067888] [G loss: 2.093941]\n",
      "[Epoch 33/5000] [Batch 0/1] [D loss: 0.069249] [G loss: 2.083033]\n",
      "[Epoch 34/5000] [Batch 0/1] [D loss: 0.061438] [G loss: 2.223851]\n",
      "[Epoch 35/5000] [Batch 0/1] [D loss: 0.051923] [G loss: 2.461931]\n",
      "[Epoch 36/5000] [Batch 0/1] [D loss: 0.052755] [G loss: 2.458928]\n",
      "[Epoch 37/5000] [Batch 0/1] [D loss: 0.093655] [G loss: 1.870551]\n",
      "[Epoch 38/5000] [Batch 0/1] [D loss: 0.161042] [G loss: 1.398944]\n",
      "[Epoch 39/5000] [Batch 0/1] [D loss: 0.209926] [G loss: 1.181862]\n",
      "[Epoch 40/5000] [Batch 0/1] [D loss: 0.239141] [G loss: 1.083126]\n",
      "[Epoch 41/5000] [Batch 0/1] [D loss: 0.179839] [G loss: 1.264192]\n",
      "[Epoch 42/5000] [Batch 0/1] [D loss: 0.124168] [G loss: 1.588073]\n",
      "[Epoch 43/5000] [Batch 0/1] [D loss: 0.101450] [G loss: 1.747881]\n",
      "[Epoch 44/5000] [Batch 0/1] [D loss: 0.084130] [G loss: 1.912672]\n",
      "[Epoch 45/5000] [Batch 0/1] [D loss: 0.074615] [G loss: 2.014354]\n",
      "[Epoch 46/5000] [Batch 0/1] [D loss: 0.074249] [G loss: 2.009720]\n",
      "[Epoch 47/5000] [Batch 0/1] [D loss: 0.075420] [G loss: 1.986695]\n",
      "[Epoch 48/5000] [Batch 0/1] [D loss: 0.076902] [G loss: 1.964556]\n",
      "[Epoch 49/5000] [Batch 0/1] [D loss: 0.079209] [G loss: 1.936779]\n",
      "[Epoch 50/5000] [Batch 0/1] [D loss: 0.084362] [G loss: 1.877492]\n",
      "[Epoch 51/5000] [Batch 0/1] [D loss: 0.091600] [G loss: 1.809022]\n",
      "[Epoch 52/5000] [Batch 0/1] [D loss: 0.127039] [G loss: 1.514763]\n",
      "[Epoch 53/5000] [Batch 0/1] [D loss: 0.186928] [G loss: 1.196493]\n",
      "[Epoch 54/5000] [Batch 0/1] [D loss: 0.233559] [G loss: 1.002815]\n",
      "[Epoch 55/5000] [Batch 0/1] [D loss: 0.260514] [G loss: 0.916856]\n",
      "[Epoch 56/5000] [Batch 0/1] [D loss: 0.274145] [G loss: 0.879633]\n",
      "[Epoch 57/5000] [Batch 0/1] [D loss: 0.280153] [G loss: 0.875558]\n",
      "[Epoch 58/5000] [Batch 0/1] [D loss: 0.239825] [G loss: 0.983904]\n",
      "[Epoch 59/5000] [Batch 0/1] [D loss: 0.204042] [G loss: 1.121502]\n",
      "[Epoch 60/5000] [Batch 0/1] [D loss: 0.161972] [G loss: 1.321854]\n",
      "[Epoch 61/5000] [Batch 0/1] [D loss: 0.142773] [G loss: 1.417288]\n",
      "[Epoch 62/5000] [Batch 0/1] [D loss: 0.147278] [G loss: 1.393488]\n",
      "[Epoch 63/5000] [Batch 0/1] [D loss: 0.165508] [G loss: 1.285769]\n",
      "[Epoch 64/5000] [Batch 0/1] [D loss: 0.202653] [G loss: 1.122251]\n",
      "[Epoch 65/5000] [Batch 0/1] [D loss: 0.250891] [G loss: 0.940182]\n",
      "[Epoch 66/5000] [Batch 0/1] [D loss: 0.317157] [G loss: 0.809582]\n",
      "[Epoch 67/5000] [Batch 0/1] [D loss: 0.689075] [G loss: 0.576186]\n",
      "[Epoch 68/5000] [Batch 0/1] [D loss: 10.024752] [G loss: 0.676734]\n",
      "[Epoch 69/5000] [Batch 0/1] [D loss: 0.506544] [G loss: 0.494282]\n",
      "[Epoch 70/5000] [Batch 0/1] [D loss: 0.511031] [G loss: 0.447231]\n",
      "[Epoch 71/5000] [Batch 0/1] [D loss: 0.518938] [G loss: 0.437808]\n",
      "[Epoch 72/5000] [Batch 0/1] [D loss: 0.505073] [G loss: 0.453034]\n",
      "[Epoch 73/5000] [Batch 0/1] [D loss: 0.490733] [G loss: 0.469794]\n",
      "[Epoch 74/5000] [Batch 0/1] [D loss: 0.470053] [G loss: 0.495371]\n",
      "[Epoch 75/5000] [Batch 0/1] [D loss: 0.438415] [G loss: 0.538063]\n",
      "[Epoch 76/5000] [Batch 0/1] [D loss: 0.403703] [G loss: 0.590677]\n",
      "[Epoch 77/5000] [Batch 0/1] [D loss: 0.365132] [G loss: 0.657516]\n",
      "[Epoch 78/5000] [Batch 0/1] [D loss: 0.331802] [G loss: 0.723815]\n",
      "[Epoch 79/5000] [Batch 0/1] [D loss: 0.302782] [G loss: 0.789511]\n",
      "[Epoch 80/5000] [Batch 0/1] [D loss: 0.269573] [G loss: 0.876331]\n",
      "[Epoch 81/5000] [Batch 0/1] [D loss: 0.256894] [G loss: 0.920331]\n",
      "[Epoch 82/5000] [Batch 0/1] [D loss: 0.263735] [G loss: 0.951126]\n",
      "[Epoch 83/5000] [Batch 0/1] [D loss: 0.290823] [G loss: 0.818945]\n",
      "[Epoch 84/5000] [Batch 0/1] [D loss: 0.301227] [G loss: 0.793046]\n",
      "[Epoch 85/5000] [Batch 0/1] [D loss: 0.292828] [G loss: 0.814014]\n",
      "[Epoch 86/5000] [Batch 0/1] [D loss: 0.276739] [G loss: 0.858600]\n",
      "[Epoch 87/5000] [Batch 0/1] [D loss: 0.271629] [G loss: 0.893233]\n",
      "[Epoch 88/5000] [Batch 0/1] [D loss: 0.272167] [G loss: 0.898867]\n",
      "[Epoch 89/5000] [Batch 0/1] [D loss: 0.316673] [G loss: 0.819323]\n",
      "[Epoch 90/5000] [Batch 0/1] [D loss: 0.441771] [G loss: 0.534654]\n",
      "[Epoch 91/5000] [Batch 0/1] [D loss: 0.496768] [G loss: 0.463769]\n",
      "[Epoch 92/5000] [Batch 0/1] [D loss: 0.475761] [G loss: 0.499103]\n",
      "[Epoch 93/5000] [Batch 0/1] [D loss: 0.838047] [G loss: 0.546681]\n",
      "[Epoch 94/5000] [Batch 0/1] [D loss: 1.035922] [G loss: 0.136266]\n",
      "[Epoch 95/5000] [Batch 0/1] [D loss: 1.281446] [G loss: 0.080986]\n",
      "[Epoch 96/5000] [Batch 0/1] [D loss: 1.224345] [G loss: 0.091325]\n",
      "[Epoch 97/5000] [Batch 0/1] [D loss: 1.021426] [G loss: 0.139343]\n",
      "[Epoch 98/5000] [Batch 0/1] [D loss: 0.825542] [G loss: 0.213247]\n",
      "[Epoch 99/5000] [Batch 0/1] [D loss: 0.607489] [G loss: 0.352157]\n",
      "[Epoch 100/5000] [Batch 0/1] [D loss: 0.434369] [G loss: 0.545833]\n",
      "[Epoch 101/5000] [Batch 0/1] [D loss: 0.323772] [G loss: 0.744425]\n",
      "[Epoch 102/5000] [Batch 0/1] [D loss: 0.264156] [G loss: 0.941153]\n",
      "[Epoch 103/5000] [Batch 0/1] [D loss: 0.301878] [G loss: 0.904813]\n",
      "[Epoch 104/5000] [Batch 0/1] [D loss: 0.364754] [G loss: 0.660199]\n",
      "[Epoch 105/5000] [Batch 0/1] [D loss: 0.362587] [G loss: 0.663842]\n",
      "[Epoch 106/5000] [Batch 0/1] [D loss: 0.434330] [G loss: 0.789382]\n",
      "[Epoch 107/5000] [Batch 0/1] [D loss: 0.478351] [G loss: 0.486028]\n",
      "[Epoch 108/5000] [Batch 0/1] [D loss: 0.517465] [G loss: 0.441063]\n",
      "[Epoch 109/5000] [Batch 0/1] [D loss: 0.479927] [G loss: 0.484626]\n",
      "[Epoch 110/5000] [Batch 0/1] [D loss: 0.408456] [G loss: 0.586526]\n",
      "[Epoch 111/5000] [Batch 0/1] [D loss: 0.357094] [G loss: 0.676885]\n",
      "[Epoch 112/5000] [Batch 0/1] [D loss: 0.305772] [G loss: 0.792754]\n",
      "[Epoch 113/5000] [Batch 0/1] [D loss: 0.435441] [G loss: 0.886837]\n",
      "[Epoch 114/5000] [Batch 0/1] [D loss: 0.472649] [G loss: 0.493912]\n",
      "[Epoch 115/5000] [Batch 0/1] [D loss: 0.657497] [G loss: 0.530085]\n",
      "[Epoch 116/5000] [Batch 0/1] [D loss: 1.310398] [G loss: 0.076132]\n",
      "[Epoch 117/5000] [Batch 0/1] [D loss: 1.318650] [G loss: 0.074510]\n",
      "[Epoch 118/5000] [Batch 0/1] [D loss: 0.823502] [G loss: 0.214163]\n",
      "[Epoch 119/5000] [Batch 0/1] [D loss: 0.390120] [G loss: 0.631372]\n",
      "[Epoch 120/5000] [Batch 0/1] [D loss: 0.460760] [G loss: 1.092015]\n",
      "[Epoch 121/5000] [Batch 0/1] [D loss: 0.337383] [G loss: 0.743832]\n",
      "[Epoch 122/5000] [Batch 0/1] [D loss: 0.410856] [G loss: 0.588798]\n",
      "[Epoch 123/5000] [Batch 0/1] [D loss: 0.571986] [G loss: 0.568286]\n",
      "[Epoch 124/5000] [Batch 0/1] [D loss: 1.082270] [G loss: 0.122218]\n",
      "[Epoch 125/5000] [Batch 0/1] [D loss: 1.047556] [G loss: 0.131705]\n",
      "[Epoch 126/5000] [Batch 0/1] [D loss: 0.757403] [G loss: 0.248673]\n",
      "[Epoch 127/5000] [Batch 0/1] [D loss: 0.483672] [G loss: 0.479487]\n",
      "[Epoch 128/5000] [Batch 0/1] [D loss: 0.311495] [G loss: 0.804740]\n",
      "[Epoch 129/5000] [Batch 0/1] [D loss: 0.238404] [G loss: 1.098902]\n",
      "[Epoch 130/5000] [Batch 0/1] [D loss: 0.202469] [G loss: 1.235345]\n",
      "[Epoch 131/5000] [Batch 0/1] [D loss: 0.206978] [G loss: 1.087391]\n",
      "[Epoch 132/5000] [Batch 0/1] [D loss: 0.208484] [G loss: 1.081574]\n",
      "[Epoch 133/5000] [Batch 0/1] [D loss: 0.207207] [G loss: 1.175420]\n",
      "[Epoch 134/5000] [Batch 0/1] [D loss: 0.253988] [G loss: 0.927688]\n",
      "[Epoch 135/5000] [Batch 0/1] [D loss: 0.272159] [G loss: 0.941352]\n",
      "[Epoch 136/5000] [Batch 0/1] [D loss: 0.338633] [G loss: 0.719236]\n",
      "[Epoch 137/5000] [Batch 0/1] [D loss: 0.493360] [G loss: 0.792876]\n",
      "[Epoch 138/5000] [Batch 0/1] [D loss: 1.106642] [G loss: 0.116505]\n",
      "[Epoch 139/5000] [Batch 0/1] [D loss: 1.090590] [G loss: 0.120141]\n",
      "[Epoch 140/5000] [Batch 0/1] [D loss: 0.715411] [G loss: 0.273454]\n",
      "[Epoch 141/5000] [Batch 0/1] [D loss: 0.327804] [G loss: 0.734032]\n",
      "[Epoch 142/5000] [Batch 0/1] [D loss: 0.578961] [G loss: 1.327197]\n",
      "[Epoch 143/5000] [Batch 0/1] [D loss: 0.743152] [G loss: 0.256654]\n",
      "[Epoch 144/5000] [Batch 0/1] [D loss: 0.883638] [G loss: 0.187960]\n",
      "[Epoch 145/5000] [Batch 0/1] [D loss: 0.734644] [G loss: 0.261814]\n",
      "[Epoch 146/5000] [Batch 0/1] [D loss: 0.541396] [G loss: 0.413582]\n",
      "[Epoch 147/5000] [Batch 0/1] [D loss: 0.341697] [G loss: 0.703253]\n",
      "[Epoch 148/5000] [Batch 0/1] [D loss: 0.285912] [G loss: 1.115076]\n",
      "[Epoch 149/5000] [Batch 0/1] [D loss: 0.299939] [G loss: 0.796486]\n",
      "[Epoch 150/5000] [Batch 0/1] [D loss: 0.297858] [G loss: 0.801600]\n",
      "[Epoch 151/5000] [Batch 0/1] [D loss: 0.244327] [G loss: 0.964579]\n",
      "[Epoch 152/5000] [Batch 0/1] [D loss: 0.461269] [G loss: 1.158272]\n",
      "[Epoch 153/5000] [Batch 0/1] [D loss: 0.681260] [G loss: 0.296941]\n",
      "[Epoch 154/5000] [Batch 0/1] [D loss: 0.807721] [G loss: 0.222694]\n",
      "[Epoch 155/5000] [Batch 0/1] [D loss: 0.686379] [G loss: 0.293117]\n",
      "[Epoch 156/5000] [Batch 0/1] [D loss: 0.545906] [G loss: 0.409384]\n",
      "[Epoch 157/5000] [Batch 0/1] [D loss: 0.414603] [G loss: 0.573822]\n",
      "[Epoch 158/5000] [Batch 0/1] [D loss: 0.303182] [G loss: 0.817865]\n",
      "[Epoch 159/5000] [Batch 0/1] [D loss: 0.443187] [G loss: 1.053365]\n",
      "[Epoch 160/5000] [Batch 0/1] [D loss: 0.457341] [G loss: 0.512527]\n",
      "[Epoch 161/5000] [Batch 0/1] [D loss: 0.499598] [G loss: 0.459776]\n",
      "[Epoch 162/5000] [Batch 0/1] [D loss: 0.423397] [G loss: 0.560322]\n",
      "[Epoch 163/5000] [Batch 0/1] [D loss: 0.310604] [G loss: 0.788359]\n",
      "[Epoch 164/5000] [Batch 0/1] [D loss: 0.462359] [G loss: 1.033002]\n",
      "[Epoch 165/5000] [Batch 0/1] [D loss: 0.487970] [G loss: 0.473246]\n",
      "[Epoch 166/5000] [Batch 0/1] [D loss: 0.524628] [G loss: 0.431276]\n",
      "[Epoch 167/5000] [Batch 0/1] [D loss: 0.422395] [G loss: 0.561833]\n",
      "[Epoch 168/5000] [Batch 0/1] [D loss: 0.304218] [G loss: 0.796140]\n",
      "[Epoch 169/5000] [Batch 0/1] [D loss: 0.365570] [G loss: 1.046267]\n",
      "[Epoch 170/5000] [Batch 0/1] [D loss: 0.344644] [G loss: 0.699141]\n",
      "[Epoch 171/5000] [Batch 0/1] [D loss: 0.356569] [G loss: 0.675398]\n",
      "[Epoch 172/5000] [Batch 0/1] [D loss: 0.306614] [G loss: 0.805362]\n",
      "[Epoch 173/5000] [Batch 0/1] [D loss: 0.364054] [G loss: 0.961309]\n",
      "[Epoch 174/5000] [Batch 0/1] [D loss: 0.403292] [G loss: 0.592053]\n",
      "[Epoch 175/5000] [Batch 0/1] [D loss: 0.391391] [G loss: 0.611769]\n",
      "[Epoch 176/5000] [Batch 0/1] [D loss: 0.306764] [G loss: 0.810367]\n",
      "[Epoch 177/5000] [Batch 0/1] [D loss: 0.391184] [G loss: 1.026070]\n",
      "[Epoch 178/5000] [Batch 0/1] [D loss: 0.431008] [G loss: 0.549296]\n",
      "[Epoch 179/5000] [Batch 0/1] [D loss: 0.425784] [G loss: 0.557238]\n",
      "[Epoch 180/5000] [Batch 0/1] [D loss: 0.315136] [G loss: 0.762776]\n",
      "[Epoch 181/5000] [Batch 0/1] [D loss: 0.274791] [G loss: 1.133814]\n",
      "[Epoch 182/5000] [Batch 0/1] [D loss: 0.282756] [G loss: 0.847796]\n",
      "[Epoch 183/5000] [Batch 0/1] [D loss: 0.264003] [G loss: 0.920449]\n",
      "[Epoch 184/5000] [Batch 0/1] [D loss: 0.349185] [G loss: 1.101709]\n",
      "[Epoch 185/5000] [Batch 0/1] [D loss: 0.520230] [G loss: 0.436302]\n",
      "[Epoch 186/5000] [Batch 0/1] [D loss: 0.457450] [G loss: 0.512299]\n",
      "[Epoch 187/5000] [Batch 0/1] [D loss: 0.300128] [G loss: 0.799688]\n",
      "[Epoch 188/5000] [Batch 0/1] [D loss: 0.280427] [G loss: 1.227612]\n",
      "[Epoch 189/5000] [Batch 0/1] [D loss: 0.262303] [G loss: 0.905835]\n",
      "[Epoch 190/5000] [Batch 0/1] [D loss: 0.254736] [G loss: 0.937194]\n",
      "[Epoch 191/5000] [Batch 0/1] [D loss: 0.281981] [G loss: 1.108949]\n",
      "[Epoch 192/5000] [Batch 0/1] [D loss: 0.323742] [G loss: 0.744311]\n",
      "[Epoch 193/5000] [Batch 0/1] [D loss: 0.275305] [G loss: 0.877772]\n",
      "[Epoch 194/5000] [Batch 0/1] [D loss: 0.320646] [G loss: 1.156006]\n",
      "[Epoch 195/5000] [Batch 0/1] [D loss: 0.366035] [G loss: 0.656441]\n",
      "[Epoch 196/5000] [Batch 0/1] [D loss: 0.313502] [G loss: 0.765200]\n",
      "[Epoch 197/5000] [Batch 0/1] [D loss: 0.218839] [G loss: 1.070833]\n",
      "[Epoch 198/5000] [Batch 0/1] [D loss: 0.333464] [G loss: 1.382401]\n",
      "[Epoch 199/5000] [Batch 0/1] [D loss: 0.430350] [G loss: 0.550118]\n",
      "[Epoch 200/5000] [Batch 0/1] [D loss: 0.404402] [G loss: 0.589664]\n",
      "[Epoch 201/5000] [Batch 0/1] [D loss: 0.274164] [G loss: 0.867964]\n",
      "[Epoch 202/5000] [Batch 0/1] [D loss: 0.270863] [G loss: 1.303290]\n",
      "[Epoch 203/5000] [Batch 0/1] [D loss: 0.257530] [G loss: 0.915261]\n",
      "[Epoch 204/5000] [Batch 0/1] [D loss: 0.249637] [G loss: 0.942206]\n",
      "[Epoch 205/5000] [Batch 0/1] [D loss: 0.257615] [G loss: 1.099408]\n",
      "[Epoch 206/5000] [Batch 0/1] [D loss: 0.294039] [G loss: 0.816315]\n",
      "[Epoch 207/5000] [Batch 0/1] [D loss: 0.271989] [G loss: 0.892739]\n",
      "[Epoch 208/5000] [Batch 0/1] [D loss: 0.286209] [G loss: 1.030772]\n",
      "[Epoch 209/5000] [Batch 0/1] [D loss: 0.298992] [G loss: 0.800081]\n",
      "[Epoch 210/5000] [Batch 0/1] [D loss: 0.271276] [G loss: 0.873757]\n",
      "[Epoch 211/5000] [Batch 0/1] [D loss: 0.234655] [G loss: 1.063056]\n",
      "[Epoch 212/5000] [Batch 0/1] [D loss: 0.232019] [G loss: 1.107333]\n",
      "[Epoch 213/5000] [Batch 0/1] [D loss: 0.238021] [G loss: 0.982671]\n",
      "[Epoch 214/5000] [Batch 0/1] [D loss: 0.230184] [G loss: 1.045827]\n",
      "[Epoch 215/5000] [Batch 0/1] [D loss: 0.247367] [G loss: 1.082345]\n",
      "[Epoch 216/5000] [Batch 0/1] [D loss: 0.275328] [G loss: 0.862603]\n",
      "[Epoch 217/5000] [Batch 0/1] [D loss: 0.255141] [G loss: 0.929223]\n",
      "[Epoch 218/5000] [Batch 0/1] [D loss: 0.267703] [G loss: 1.065570]\n",
      "[Epoch 219/5000] [Batch 0/1] [D loss: 0.277740] [G loss: 0.855089]\n",
      "[Epoch 220/5000] [Batch 0/1] [D loss: 0.261114] [G loss: 0.904957]\n",
      "[Epoch 221/5000] [Batch 0/1] [D loss: 0.249094] [G loss: 1.057317]\n",
      "[Epoch 222/5000] [Batch 0/1] [D loss: 0.238870] [G loss: 0.991651]\n",
      "[Epoch 223/5000] [Batch 0/1] [D loss: 0.232367] [G loss: 1.051646]\n",
      "[Epoch 224/5000] [Batch 0/1] [D loss: 0.230852] [G loss: 1.071898]\n",
      "[Epoch 225/5000] [Batch 0/1] [D loss: 0.226403] [G loss: 1.039791]\n",
      "[Epoch 226/5000] [Batch 0/1] [D loss: 0.220467] [G loss: 1.092058]\n",
      "[Epoch 227/5000] [Batch 0/1] [D loss: 0.215979] [G loss: 1.094608]\n",
      "[Epoch 228/5000] [Batch 0/1] [D loss: 0.215942] [G loss: 1.090856]\n",
      "[Epoch 229/5000] [Batch 0/1] [D loss: 0.216283] [G loss: 1.104197]\n",
      "[Epoch 230/5000] [Batch 0/1] [D loss: 0.223195] [G loss: 1.060152]\n",
      "[Epoch 231/5000] [Batch 0/1] [D loss: 0.234500] [G loss: 1.037037]\n",
      "[Epoch 232/5000] [Batch 0/1] [D loss: 0.246093] [G loss: 0.970366]\n",
      "[Epoch 233/5000] [Batch 0/1] [D loss: 0.258010] [G loss: 0.977006]\n",
      "[Epoch 234/5000] [Batch 0/1] [D loss: 0.275638] [G loss: 0.869913]\n",
      "[Epoch 235/5000] [Batch 0/1] [D loss: 0.282365] [G loss: 0.921954]\n",
      "[Epoch 236/5000] [Batch 0/1] [D loss: 0.296512] [G loss: 0.808570]\n",
      "[Epoch 237/5000] [Batch 0/1] [D loss: 0.280845] [G loss: 0.897952]\n",
      "[Epoch 238/5000] [Batch 0/1] [D loss: 0.278916] [G loss: 0.883666]\n",
      "[Epoch 239/5000] [Batch 0/1] [D loss: 0.277141] [G loss: 0.898006]\n",
      "[Epoch 240/5000] [Batch 0/1] [D loss: 0.275550] [G loss: 0.892221]\n",
      "[Epoch 241/5000] [Batch 0/1] [D loss: 0.273957] [G loss: 0.919131]\n",
      "[Epoch 242/5000] [Batch 0/1] [D loss: 0.278599] [G loss: 0.862930]\n",
      "[Epoch 243/5000] [Batch 0/1] [D loss: 0.296839] [G loss: 0.989806]\n",
      "[Epoch 244/5000] [Batch 0/1] [D loss: 0.377694] [G loss: 0.634783]\n",
      "[Epoch 245/5000] [Batch 0/1] [D loss: 0.324710] [G loss: 0.739159]\n",
      "[Epoch 246/5000] [Batch 0/1] [D loss: 0.264264] [G loss: 1.048732]\n",
      "[Epoch 247/5000] [Batch 0/1] [D loss: 0.288953] [G loss: 0.826057]\n",
      "[Epoch 248/5000] [Batch 0/1] [D loss: 0.249857] [G loss: 0.984627]\n",
      "[Epoch 249/5000] [Batch 0/1] [D loss: 0.286117] [G loss: 1.099027]\n",
      "[Epoch 250/5000] [Batch 0/1] [D loss: 0.382108] [G loss: 0.627124]\n",
      "[Epoch 251/5000] [Batch 0/1] [D loss: 0.320533] [G loss: 0.748505]\n",
      "[Epoch 252/5000] [Batch 0/1] [D loss: 0.192951] [G loss: 1.171112]\n",
      "[Epoch 253/5000] [Batch 0/1] [D loss: 0.332434] [G loss: 1.527817]\n",
      "[Epoch 254/5000] [Batch 0/1] [D loss: 0.333490] [G loss: 0.733152]\n",
      "[Epoch 255/5000] [Batch 0/1] [D loss: 0.331187] [G loss: 0.725099]\n",
      "[Epoch 256/5000] [Batch 0/1] [D loss: 0.235086] [G loss: 0.980989]\n",
      "[Epoch 257/5000] [Batch 0/1] [D loss: 0.201223] [G loss: 1.359477]\n",
      "[Epoch 258/5000] [Batch 0/1] [D loss: 0.223177] [G loss: 1.026291]\n",
      "[Epoch 259/5000] [Batch 0/1] [D loss: 0.232456] [G loss: 1.021852]\n",
      "[Epoch 260/5000] [Batch 0/1] [D loss: 0.307512] [G loss: 1.053253]\n",
      "[Epoch 261/5000] [Batch 0/1] [D loss: 0.421793] [G loss: 0.562856]\n",
      "[Epoch 262/5000] [Batch 0/1] [D loss: 0.384472] [G loss: 0.623623]\n",
      "[Epoch 263/5000] [Batch 0/1] [D loss: 0.388289] [G loss: 0.903798]\n",
      "[Epoch 264/5000] [Batch 0/1] [D loss: 0.409844] [G loss: 0.582243]\n",
      "[Epoch 265/5000] [Batch 0/1] [D loss: 0.352107] [G loss: 0.694038]\n",
      "[Epoch 266/5000] [Batch 0/1] [D loss: 0.390123] [G loss: 0.925086]\n",
      "[Epoch 267/5000] [Batch 0/1] [D loss: 0.364435] [G loss: 0.660110]\n",
      "[Epoch 268/5000] [Batch 0/1] [D loss: 0.299580] [G loss: 0.835275]\n",
      "[Epoch 269/5000] [Batch 0/1] [D loss: 0.314786] [G loss: 0.985577]\n",
      "[Epoch 270/5000] [Batch 0/1] [D loss: 0.386454] [G loss: 0.621032]\n",
      "[Epoch 271/5000] [Batch 0/1] [D loss: 0.282372] [G loss: 0.842400]\n",
      "[Epoch 272/5000] [Batch 0/1] [D loss: 0.160290] [G loss: 1.302588]\n",
      "[Epoch 273/5000] [Batch 0/1] [D loss: 0.276171] [G loss: 1.640850]\n",
      "[Epoch 274/5000] [Batch 0/1] [D loss: 0.367191] [G loss: 0.658648]\n",
      "[Epoch 275/5000] [Batch 0/1] [D loss: 0.379239] [G loss: 0.638683]\n",
      "[Epoch 276/5000] [Batch 0/1] [D loss: 0.259664] [G loss: 0.926273]\n",
      "[Epoch 277/5000] [Batch 0/1] [D loss: 0.207987] [G loss: 1.313628]\n",
      "[Epoch 278/5000] [Batch 0/1] [D loss: 0.209196] [G loss: 1.201370]\n",
      "[Epoch 279/5000] [Batch 0/1] [D loss: 0.133891] [G loss: 1.580958]\n",
      "[Epoch 280/5000] [Batch 0/1] [D loss: 0.069831] [G loss: 2.172541]\n",
      "[Epoch 281/5000] [Batch 0/1] [D loss: 0.100785] [G loss: 1.736871]\n",
      "[Epoch 282/5000] [Batch 0/1] [D loss: 0.109819] [G loss: 1.703683]\n",
      "[Epoch 283/5000] [Batch 0/1] [D loss: 0.468775] [G loss: 1.517357]\n",
      "[Epoch 284/5000] [Batch 0/1] [D loss: 3.000059] [G loss: 0.006310]\n",
      "[Epoch 285/5000] [Batch 0/1] [D loss: 0.022044] [G loss: 3.312921]\n",
      "[Epoch 286/5000] [Batch 0/1] [D loss: 0.038333] [G loss: 2.828070]\n",
      "[Epoch 287/5000] [Batch 0/1] [D loss: 0.421184] [G loss: 0.680655]\n",
      "[Epoch 288/5000] [Batch 0/1] [D loss: 0.472399] [G loss: 0.496509]\n",
      "[Epoch 289/5000] [Batch 0/1] [D loss: 0.496074] [G loss: 0.654173]\n",
      "[Epoch 290/5000] [Batch 0/1] [D loss: 0.332814] [G loss: 0.727445]\n",
      "[Epoch 291/5000] [Batch 0/1] [D loss: 0.267014] [G loss: 0.897811]\n",
      "[Epoch 292/5000] [Batch 0/1] [D loss: 0.247520] [G loss: 0.999209]\n",
      "[Epoch 293/5000] [Batch 0/1] [D loss: 0.505128] [G loss: 1.108009]\n",
      "[Epoch 294/5000] [Batch 0/1] [D loss: 0.817748] [G loss: 0.223912]\n",
      "[Epoch 295/5000] [Batch 0/1] [D loss: 0.703185] [G loss: 0.284232]\n",
      "[Epoch 296/5000] [Batch 0/1] [D loss: 0.371667] [G loss: 0.744607]\n",
      "[Epoch 297/5000] [Batch 0/1] [D loss: 0.313178] [G loss: 0.850768]\n",
      "[Epoch 298/5000] [Batch 0/1] [D loss: 0.321893] [G loss: 0.777799]\n",
      "[Epoch 299/5000] [Batch 0/1] [D loss: 0.539208] [G loss: 1.228529]\n",
      "[Epoch 300/5000] [Batch 0/1] [D loss: 1.129823] [G loss: 0.113336]\n",
      "[Epoch 301/5000] [Batch 0/1] [D loss: 0.720103] [G loss: 0.271923]\n",
      "[Epoch 302/5000] [Batch 0/1] [D loss: 0.151935] [G loss: 1.356032]\n",
      "[Epoch 303/5000] [Batch 0/1] [D loss: 0.260244] [G loss: 2.301099]\n",
      "[Epoch 304/5000] [Batch 0/1] [D loss: 0.493101] [G loss: 0.468195]\n",
      "[Epoch 305/5000] [Batch 0/1] [D loss: 0.549724] [G loss: 0.406129]\n",
      "[Epoch 306/5000] [Batch 0/1] [D loss: 0.367989] [G loss: 0.652981]\n",
      "[Epoch 307/5000] [Batch 0/1] [D loss: 0.361700] [G loss: 1.093651]\n",
      "[Epoch 308/5000] [Batch 0/1] [D loss: 0.630828] [G loss: 0.334846]\n",
      "[Epoch 309/5000] [Batch 0/1] [D loss: 0.524130] [G loss: 0.432984]\n",
      "[Epoch 310/5000] [Batch 0/1] [D loss: 0.267720] [G loss: 0.882235]\n",
      "[Epoch 311/5000] [Batch 0/1] [D loss: 0.457494] [G loss: 1.609218]\n",
      "[Epoch 312/5000] [Batch 0/1] [D loss: 0.532252] [G loss: 0.423563]\n",
      "[Epoch 313/5000] [Batch 0/1] [D loss: 0.532201] [G loss: 0.423690]\n",
      "[Epoch 314/5000] [Batch 0/1] [D loss: 0.300823] [G loss: 0.794144]\n",
      "[Epoch 315/5000] [Batch 0/1] [D loss: 0.162878] [G loss: 1.307964]\n",
      "[Epoch 316/5000] [Batch 0/1] [D loss: 0.366111] [G loss: 1.703953]\n",
      "[Epoch 317/5000] [Batch 0/1] [D loss: 0.480935] [G loss: 0.482832]\n",
      "[Epoch 318/5000] [Batch 0/1] [D loss: 0.542548] [G loss: 0.413674]\n",
      "[Epoch 319/5000] [Batch 0/1] [D loss: 0.396550] [G loss: 0.603525]\n",
      "[Epoch 320/5000] [Batch 0/1] [D loss: 0.277902] [G loss: 0.859422]\n",
      "[Epoch 321/5000] [Batch 0/1] [D loss: 0.397549] [G loss: 1.189624]\n",
      "[Epoch 322/5000] [Batch 0/1] [D loss: 0.412509] [G loss: 0.577746]\n",
      "[Epoch 323/5000] [Batch 0/1] [D loss: 0.421686] [G loss: 0.563316]\n",
      "[Epoch 324/5000] [Batch 0/1] [D loss: 0.299133] [G loss: 0.800864]\n",
      "[Epoch 325/5000] [Batch 0/1] [D loss: 0.269545] [G loss: 1.214625]\n",
      "[Epoch 326/5000] [Batch 0/1] [D loss: 0.223512] [G loss: 1.026490]\n",
      "[Epoch 327/5000] [Batch 0/1] [D loss: 0.184458] [G loss: 1.192863]\n",
      "[Epoch 328/5000] [Batch 0/1] [D loss: 0.180853] [G loss: 1.506666]\n",
      "[Epoch 329/5000] [Batch 0/1] [D loss: 0.196926] [G loss: 1.129729]\n",
      "[Epoch 330/5000] [Batch 0/1] [D loss: 0.188761] [G loss: 1.175852]\n",
      "[Epoch 331/5000] [Batch 0/1] [D loss: 0.235960] [G loss: 1.301249]\n",
      "[Epoch 332/5000] [Batch 0/1] [D loss: 0.307598] [G loss: 0.778672]\n",
      "[Epoch 333/5000] [Batch 0/1] [D loss: 0.312016] [G loss: 0.768258]\n",
      "[Epoch 334/5000] [Batch 0/1] [D loss: 0.249324] [G loss: 0.940086]\n",
      "[Epoch 335/5000] [Batch 0/1] [D loss: 0.270786] [G loss: 1.162948]\n",
      "[Epoch 336/5000] [Batch 0/1] [D loss: 0.259910] [G loss: 0.908437]\n",
      "[Epoch 337/5000] [Batch 0/1] [D loss: 0.257960] [G loss: 0.915908]\n",
      "[Epoch 338/5000] [Batch 0/1] [D loss: 0.245175] [G loss: 1.042640]\n",
      "[Epoch 339/5000] [Batch 0/1] [D loss: 0.241381] [G loss: 1.026262]\n",
      "[Epoch 340/5000] [Batch 0/1] [D loss: 0.243455] [G loss: 0.977853]\n",
      "[Epoch 341/5000] [Batch 0/1] [D loss: 0.245004] [G loss: 1.013222]\n",
      "[Epoch 342/5000] [Batch 0/1] [D loss: 0.250985] [G loss: 0.974899]\n",
      "[Epoch 343/5000] [Batch 0/1] [D loss: 0.268154] [G loss: 0.926793]\n",
      "[Epoch 344/5000] [Batch 0/1] [D loss: 0.284838] [G loss: 0.896388]\n",
      "[Epoch 345/5000] [Batch 0/1] [D loss: 0.302703] [G loss: 0.815968]\n",
      "[Epoch 346/5000] [Batch 0/1] [D loss: 0.318427] [G loss: 0.880952]\n",
      "[Epoch 347/5000] [Batch 0/1] [D loss: 0.335478] [G loss: 0.718337]\n",
      "[Epoch 348/5000] [Batch 0/1] [D loss: 0.248572] [G loss: 0.990121]\n",
      "[Epoch 349/5000] [Batch 0/1] [D loss: 0.258365] [G loss: 1.227479]\n",
      "[Epoch 350/5000] [Batch 0/1] [D loss: 0.311203] [G loss: 0.769758]\n",
      "[Epoch 351/5000] [Batch 0/1] [D loss: 0.222738] [G loss: 1.023741]\n",
      "[Epoch 352/5000] [Batch 0/1] [D loss: 0.155136] [G loss: 1.502823]\n",
      "[Epoch 353/5000] [Batch 0/1] [D loss: 0.146289] [G loss: 1.432209]\n",
      "[Epoch 354/5000] [Batch 0/1] [D loss: 0.156248] [G loss: 1.358160]\n",
      "[Epoch 355/5000] [Batch 0/1] [D loss: 0.180407] [G loss: 1.300185]\n",
      "[Epoch 356/5000] [Batch 0/1] [D loss: 0.227373] [G loss: 1.010112]\n",
      "[Epoch 357/5000] [Batch 0/1] [D loss: 0.265553] [G loss: 1.111487]\n",
      "[Epoch 358/5000] [Batch 0/1] [D loss: 0.420344] [G loss: 0.565969]\n",
      "[Epoch 359/5000] [Batch 0/1] [D loss: 0.355484] [G loss: 0.676543]\n",
      "[Epoch 360/5000] [Batch 0/1] [D loss: 0.329743] [G loss: 1.069577]\n",
      "[Epoch 361/5000] [Batch 0/1] [D loss: 0.342455] [G loss: 0.701835]\n",
      "[Epoch 362/5000] [Batch 0/1] [D loss: 0.285979] [G loss: 0.832620]\n",
      "[Epoch 363/5000] [Batch 0/1] [D loss: 0.255335] [G loss: 1.203066]\n",
      "[Epoch 364/5000] [Batch 0/1] [D loss: 0.212125] [G loss: 1.092679]\n",
      "[Epoch 365/5000] [Batch 0/1] [D loss: 0.204045] [G loss: 1.124659]\n",
      "[Epoch 366/5000] [Batch 0/1] [D loss: 0.224682] [G loss: 1.241785]\n",
      "[Epoch 367/5000] [Batch 0/1] [D loss: 0.303640] [G loss: 0.787426]\n",
      "[Epoch 368/5000] [Batch 0/1] [D loss: 0.282614] [G loss: 0.841192]\n",
      "[Epoch 369/5000] [Batch 0/1] [D loss: 0.267886] [G loss: 1.054103]\n",
      "[Epoch 370/5000] [Batch 0/1] [D loss: 0.275054] [G loss: 0.863501]\n",
      "[Epoch 371/5000] [Batch 0/1] [D loss: 0.260720] [G loss: 0.934222]\n",
      "[Epoch 372/5000] [Batch 0/1] [D loss: 0.286826] [G loss: 1.028986]\n",
      "[Epoch 373/5000] [Batch 0/1] [D loss: 0.338913] [G loss: 0.709366]\n",
      "[Epoch 374/5000] [Batch 0/1] [D loss: 0.319455] [G loss: 0.751390]\n",
      "[Epoch 375/5000] [Batch 0/1] [D loss: 0.248012] [G loss: 0.951802]\n",
      "[Epoch 376/5000] [Batch 0/1] [D loss: 0.280876] [G loss: 1.175989]\n",
      "[Epoch 377/5000] [Batch 0/1] [D loss: 0.259924] [G loss: 0.904443]\n",
      "[Epoch 378/5000] [Batch 0/1] [D loss: 0.255121] [G loss: 0.918912]\n",
      "[Epoch 379/5000] [Batch 0/1] [D loss: 0.214264] [G loss: 1.084622]\n",
      "[Epoch 380/5000] [Batch 0/1] [D loss: 0.272252] [G loss: 1.239236]\n",
      "[Epoch 381/5000] [Batch 0/1] [D loss: 0.308439] [G loss: 0.777854]\n",
      "[Epoch 382/5000] [Batch 0/1] [D loss: 0.296136] [G loss: 0.806645]\n",
      "[Epoch 383/5000] [Batch 0/1] [D loss: 0.225479] [G loss: 1.049879]\n",
      "[Epoch 384/5000] [Batch 0/1] [D loss: 0.277581] [G loss: 1.292081]\n",
      "[Epoch 385/5000] [Batch 0/1] [D loss: 0.273510] [G loss: 0.865889]\n",
      "[Epoch 386/5000] [Batch 0/1] [D loss: 0.255024] [G loss: 0.920048]\n",
      "[Epoch 387/5000] [Batch 0/1] [D loss: 0.201728] [G loss: 1.188444]\n",
      "[Epoch 388/5000] [Batch 0/1] [D loss: 0.234605] [G loss: 1.211845]\n",
      "[Epoch 389/5000] [Batch 0/1] [D loss: 0.297687] [G loss: 0.803980]\n",
      "[Epoch 390/5000] [Batch 0/1] [D loss: 0.263420] [G loss: 0.910338]\n",
      "[Epoch 391/5000] [Batch 0/1] [D loss: 0.357001] [G loss: 1.194168]\n",
      "[Epoch 392/5000] [Batch 0/1] [D loss: 0.333385] [G loss: 0.721283]\n",
      "[Epoch 393/5000] [Batch 0/1] [D loss: 0.284983] [G loss: 0.835506]\n",
      "[Epoch 394/5000] [Batch 0/1] [D loss: 0.217208] [G loss: 1.153816]\n",
      "[Epoch 395/5000] [Batch 0/1] [D loss: 0.208790] [G loss: 1.227283]\n",
      "[Epoch 396/5000] [Batch 0/1] [D loss: 0.221820] [G loss: 1.035424]\n",
      "[Epoch 397/5000] [Batch 0/1] [D loss: 0.217518] [G loss: 1.085485]\n",
      "[Epoch 398/5000] [Batch 0/1] [D loss: 0.249840] [G loss: 1.166312]\n",
      "[Epoch 399/5000] [Batch 0/1] [D loss: 0.301875] [G loss: 0.793245]\n",
      "[Epoch 400/5000] [Batch 0/1] [D loss: 0.283594] [G loss: 0.845643]\n",
      "[Epoch 401/5000] [Batch 0/1] [D loss: 0.336045] [G loss: 1.057191]\n",
      "[Epoch 402/5000] [Batch 0/1] [D loss: 0.332933] [G loss: 0.722863]\n",
      "[Epoch 403/5000] [Batch 0/1] [D loss: 0.317758] [G loss: 0.756813]\n",
      "[Epoch 404/5000] [Batch 0/1] [D loss: 0.274285] [G loss: 0.962049]\n",
      "[Epoch 405/5000] [Batch 0/1] [D loss: 0.263516] [G loss: 0.985047]\n",
      "[Epoch 406/5000] [Batch 0/1] [D loss: 0.268716] [G loss: 0.900812]\n",
      "[Epoch 407/5000] [Batch 0/1] [D loss: 0.263143] [G loss: 1.004026]\n",
      "[Epoch 408/5000] [Batch 0/1] [D loss: 0.258457] [G loss: 0.932136]\n",
      "[Epoch 409/5000] [Batch 0/1] [D loss: 0.241905] [G loss: 1.070062]\n",
      "[Epoch 410/5000] [Batch 0/1] [D loss: 0.223070] [G loss: 1.061105]\n",
      "[Epoch 411/5000] [Batch 0/1] [D loss: 0.210543] [G loss: 1.195769]\n",
      "[Epoch 412/5000] [Batch 0/1] [D loss: 0.203973] [G loss: 1.131948]\n",
      "[Epoch 413/5000] [Batch 0/1] [D loss: 0.197187] [G loss: 1.274006]\n",
      "[Epoch 414/5000] [Batch 0/1] [D loss: 0.197587] [G loss: 1.147026]\n",
      "[Epoch 415/5000] [Batch 0/1] [D loss: 0.195876] [G loss: 1.378655]\n",
      "[Epoch 416/5000] [Batch 0/1] [D loss: 0.225556] [G loss: 1.016275]\n",
      "[Epoch 417/5000] [Batch 0/1] [D loss: 0.176996] [G loss: 1.341548]\n",
      "[Epoch 418/5000] [Batch 0/1] [D loss: 0.178754] [G loss: 1.373190]\n",
      "[Epoch 419/5000] [Batch 0/1] [D loss: 0.220321] [G loss: 1.039157]\n",
      "[Epoch 420/5000] [Batch 0/1] [D loss: 0.231210] [G loss: 1.308251]\n",
      "[Epoch 421/5000] [Batch 0/1] [D loss: 0.338656] [G loss: 0.711986]\n",
      "[Epoch 422/5000] [Batch 0/1] [D loss: 0.251252] [G loss: 0.966415]\n",
      "[Epoch 423/5000] [Batch 0/1] [D loss: 0.406630] [G loss: 1.317392]\n",
      "[Epoch 424/5000] [Batch 0/1] [D loss: 0.384009] [G loss: 0.624444]\n",
      "[Epoch 425/5000] [Batch 0/1] [D loss: 0.308848] [G loss: 0.775924]\n",
      "[Epoch 426/5000] [Batch 0/1] [D loss: 0.268915] [G loss: 1.236384]\n",
      "[Epoch 427/5000] [Batch 0/1] [D loss: 0.262443] [G loss: 0.897562]\n",
      "[Epoch 428/5000] [Batch 0/1] [D loss: 0.219451] [G loss: 1.050846]\n",
      "[Epoch 429/5000] [Batch 0/1] [D loss: 0.282142] [G loss: 1.331651]\n",
      "[Epoch 430/5000] [Batch 0/1] [D loss: 0.300446] [G loss: 0.795403]\n",
      "[Epoch 431/5000] [Batch 0/1] [D loss: 0.286174] [G loss: 0.831411]\n",
      "[Epoch 432/5000] [Batch 0/1] [D loss: 0.232580] [G loss: 1.126198]\n",
      "[Epoch 433/5000] [Batch 0/1] [D loss: 0.236151] [G loss: 1.035712]\n",
      "[Epoch 434/5000] [Batch 0/1] [D loss: 0.247886] [G loss: 0.980914]\n",
      "[Epoch 435/5000] [Batch 0/1] [D loss: 0.263777] [G loss: 0.993690]\n",
      "[Epoch 436/5000] [Batch 0/1] [D loss: 0.282137] [G loss: 0.849964]\n",
      "[Epoch 437/5000] [Batch 0/1] [D loss: 0.285735] [G loss: 0.968899]\n",
      "[Epoch 438/5000] [Batch 0/1] [D loss: 0.297748] [G loss: 0.805850]\n",
      "[Epoch 439/5000] [Batch 0/1] [D loss: 0.261679] [G loss: 0.939736]\n",
      "[Epoch 440/5000] [Batch 0/1] [D loss: 0.261607] [G loss: 1.081479]\n",
      "[Epoch 441/5000] [Batch 0/1] [D loss: 0.261230] [G loss: 0.902392]\n",
      "[Epoch 442/5000] [Batch 0/1] [D loss: 0.226972] [G loss: 1.027217]\n",
      "[Epoch 443/5000] [Batch 0/1] [D loss: 0.246602] [G loss: 1.256583]\n",
      "[Epoch 444/5000] [Batch 0/1] [D loss: 0.249874] [G loss: 0.935802]\n",
      "[Epoch 445/5000] [Batch 0/1] [D loss: 0.229963] [G loss: 1.003578]\n",
      "[Epoch 446/5000] [Batch 0/1] [D loss: 0.215279] [G loss: 1.257386]\n",
      "[Epoch 447/5000] [Batch 0/1] [D loss: 0.215645] [G loss: 1.067723]\n",
      "[Epoch 448/5000] [Batch 0/1] [D loss: 0.213614] [G loss: 1.131059]\n",
      "[Epoch 449/5000] [Batch 0/1] [D loss: 0.225969] [G loss: 1.156765]\n",
      "[Epoch 450/5000] [Batch 0/1] [D loss: 0.245759] [G loss: 0.960862]\n",
      "[Epoch 451/5000] [Batch 0/1] [D loss: 0.241463] [G loss: 1.094893]\n",
      "[Epoch 452/5000] [Batch 0/1] [D loss: 0.249670] [G loss: 0.967477]\n",
      "[Epoch 453/5000] [Batch 0/1] [D loss: 0.261622] [G loss: 1.063346]\n",
      "[Epoch 454/5000] [Batch 0/1] [D loss: 0.282066] [G loss: 0.852311]\n",
      "[Epoch 455/5000] [Batch 0/1] [D loss: 0.281672] [G loss: 1.068442]\n",
      "[Epoch 456/5000] [Batch 0/1] [D loss: 0.312386] [G loss: 0.773559]\n",
      "[Epoch 457/5000] [Batch 0/1] [D loss: 0.305038] [G loss: 1.110216]\n",
      "[Epoch 458/5000] [Batch 0/1] [D loss: 0.317942] [G loss: 0.756604]\n",
      "[Epoch 459/5000] [Batch 0/1] [D loss: 0.250666] [G loss: 1.113222]\n",
      "[Epoch 460/5000] [Batch 0/1] [D loss: 0.229061] [G loss: 1.050907]\n",
      "[Epoch 461/5000] [Batch 0/1] [D loss: 0.229038] [G loss: 1.273101]\n",
      "[Epoch 462/5000] [Batch 0/1] [D loss: 0.282933] [G loss: 0.840868]\n",
      "[Epoch 463/5000] [Batch 0/1] [D loss: 0.221369] [G loss: 1.199919]\n",
      "[Epoch 464/5000] [Batch 0/1] [D loss: 0.219392] [G loss: 1.090190]\n",
      "[Epoch 465/5000] [Batch 0/1] [D loss: 0.231885] [G loss: 1.151675]\n",
      "[Epoch 466/5000] [Batch 0/1] [D loss: 0.260078] [G loss: 0.909220]\n",
      "[Epoch 467/5000] [Batch 0/1] [D loss: 0.260306] [G loss: 1.178016]\n",
      "[Epoch 468/5000] [Batch 0/1] [D loss: 0.297373] [G loss: 0.803677]\n",
      "[Epoch 469/5000] [Batch 0/1] [D loss: 0.243503] [G loss: 0.980050]\n",
      "[Epoch 470/5000] [Batch 0/1] [D loss: 0.305147] [G loss: 1.296950]\n",
      "[Epoch 471/5000] [Batch 0/1] [D loss: 0.290864] [G loss: 0.819994]\n",
      "[Epoch 472/5000] [Batch 0/1] [D loss: 0.265925] [G loss: 0.889323]\n",
      "[Epoch 473/5000] [Batch 0/1] [D loss: 0.248041] [G loss: 1.207787]\n",
      "[Epoch 474/5000] [Batch 0/1] [D loss: 0.230561] [G loss: 1.017717]\n",
      "[Epoch 475/5000] [Batch 0/1] [D loss: 0.225130] [G loss: 1.116587]\n",
      "[Epoch 476/5000] [Batch 0/1] [D loss: 0.233201] [G loss: 1.076886]\n",
      "[Epoch 477/5000] [Batch 0/1] [D loss: 0.241144] [G loss: 1.007328]\n",
      "[Epoch 478/5000] [Batch 0/1] [D loss: 0.242382] [G loss: 1.077543]\n",
      "[Epoch 479/5000] [Batch 0/1] [D loss: 0.239134] [G loss: 1.007616]\n",
      "[Epoch 480/5000] [Batch 0/1] [D loss: 0.234989] [G loss: 1.150014]\n",
      "[Epoch 481/5000] [Batch 0/1] [D loss: 0.238318] [G loss: 0.990525]\n",
      "[Epoch 482/5000] [Batch 0/1] [D loss: 0.242592] [G loss: 1.244920]\n",
      "[Epoch 483/5000] [Batch 0/1] [D loss: 0.261978] [G loss: 0.902163]\n",
      "[Epoch 484/5000] [Batch 0/1] [D loss: 0.227245] [G loss: 1.240588]\n",
      "[Epoch 485/5000] [Batch 0/1] [D loss: 0.225435] [G loss: 1.039148]\n",
      "[Epoch 486/5000] [Batch 0/1] [D loss: 0.249195] [G loss: 1.365688]\n",
      "[Epoch 487/5000] [Batch 0/1] [D loss: 0.334420] [G loss: 0.719051]\n",
      "[Epoch 488/5000] [Batch 0/1] [D loss: 0.239143] [G loss: 1.062297]\n",
      "[Epoch 489/5000] [Batch 0/1] [D loss: 0.301599] [G loss: 1.207123]\n",
      "[Epoch 490/5000] [Batch 0/1] [D loss: 0.368344] [G loss: 0.652773]\n",
      "[Epoch 491/5000] [Batch 0/1] [D loss: 0.265411] [G loss: 0.902567]\n",
      "[Epoch 492/5000] [Batch 0/1] [D loss: 0.362673] [G loss: 1.453824]\n",
      "[Epoch 493/5000] [Batch 0/1] [D loss: 0.252520] [G loss: 0.934723]\n",
      "[Epoch 494/5000] [Batch 0/1] [D loss: 0.222179] [G loss: 1.068020]\n",
      "[Epoch 495/5000] [Batch 0/1] [D loss: 0.263915] [G loss: 1.329664]\n",
      "[Epoch 496/5000] [Batch 0/1] [D loss: 0.288567] [G loss: 0.827760]\n",
      "[Epoch 497/5000] [Batch 0/1] [D loss: 0.248136] [G loss: 0.991012]\n",
      "[Epoch 498/5000] [Batch 0/1] [D loss: 0.312393] [G loss: 1.250748]\n",
      "[Epoch 499/5000] [Batch 0/1] [D loss: 0.325402] [G loss: 0.741537]\n",
      "[Epoch 500/5000] [Batch 0/1] [D loss: 0.257196] [G loss: 1.015471]\n",
      "[Epoch 501/5000] [Batch 0/1] [D loss: 0.267541] [G loss: 1.151783]\n",
      "[Epoch 502/5000] [Batch 0/1] [D loss: 0.286235] [G loss: 0.841014]\n",
      "[Epoch 503/5000] [Batch 0/1] [D loss: 0.257333] [G loss: 1.195824]\n",
      "[Epoch 504/5000] [Batch 0/1] [D loss: 0.234772] [G loss: 1.013511]\n",
      "[Epoch 505/5000] [Batch 0/1] [D loss: 0.226745] [G loss: 1.270314]\n",
      "[Epoch 506/5000] [Batch 0/1] [D loss: 0.230714] [G loss: 1.010733]\n",
      "[Epoch 507/5000] [Batch 0/1] [D loss: 0.221201] [G loss: 1.324672]\n",
      "[Epoch 508/5000] [Batch 0/1] [D loss: 0.234357] [G loss: 0.990108]\n",
      "[Epoch 509/5000] [Batch 0/1] [D loss: 0.203380] [G loss: 1.344460]\n",
      "[Epoch 510/5000] [Batch 0/1] [D loss: 0.216595] [G loss: 1.056950]\n",
      "[Epoch 511/5000] [Batch 0/1] [D loss: 0.226492] [G loss: 1.402310]\n",
      "[Epoch 512/5000] [Batch 0/1] [D loss: 0.297794] [G loss: 0.802256]\n",
      "[Epoch 513/5000] [Batch 0/1] [D loss: 0.207571] [G loss: 1.172793]\n",
      "[Epoch 514/5000] [Batch 0/1] [D loss: 0.280398] [G loss: 1.466017]\n",
      "[Epoch 515/5000] [Batch 0/1] [D loss: 0.326593] [G loss: 0.735444]\n",
      "[Epoch 516/5000] [Batch 0/1] [D loss: 0.217351] [G loss: 1.055513]\n",
      "[Epoch 517/5000] [Batch 0/1] [D loss: 0.343352] [G loss: 1.668227]\n",
      "[Epoch 518/5000] [Batch 0/1] [D loss: 0.256460] [G loss: 0.927068]\n",
      "[Epoch 519/5000] [Batch 0/1] [D loss: 0.264013] [G loss: 0.962475]\n",
      "[Epoch 520/5000] [Batch 0/1] [D loss: 0.303042] [G loss: 1.037372]\n",
      "[Epoch 521/5000] [Batch 0/1] [D loss: 0.314519] [G loss: 0.767662]\n",
      "[Epoch 522/5000] [Batch 0/1] [D loss: 0.241471] [G loss: 1.120660]\n",
      "[Epoch 523/5000] [Batch 0/1] [D loss: 0.213606] [G loss: 1.170717]\n",
      "[Epoch 524/5000] [Batch 0/1] [D loss: 0.203097] [G loss: 1.161634]\n",
      "[Epoch 525/5000] [Batch 0/1] [D loss: 0.206314] [G loss: 1.290085]\n",
      "[Epoch 526/5000] [Batch 0/1] [D loss: 0.218516] [G loss: 1.055024]\n",
      "[Epoch 527/5000] [Batch 0/1] [D loss: 0.208764] [G loss: 1.413177]\n",
      "[Epoch 528/5000] [Batch 0/1] [D loss: 0.232972] [G loss: 0.995825]\n",
      "[Epoch 529/5000] [Batch 0/1] [D loss: 0.217349] [G loss: 1.336351]\n",
      "[Epoch 530/5000] [Batch 0/1] [D loss: 0.235268] [G loss: 0.995411]\n",
      "[Epoch 531/5000] [Batch 0/1] [D loss: 0.236142] [G loss: 1.307683]\n",
      "[Epoch 532/5000] [Batch 0/1] [D loss: 0.255984] [G loss: 0.924349]\n",
      "[Epoch 533/5000] [Batch 0/1] [D loss: 0.232437] [G loss: 1.289422]\n",
      "[Epoch 534/5000] [Batch 0/1] [D loss: 0.233371] [G loss: 1.010993]\n",
      "[Epoch 535/5000] [Batch 0/1] [D loss: 0.236125] [G loss: 1.241940]\n",
      "[Epoch 536/5000] [Batch 0/1] [D loss: 0.244148] [G loss: 0.964181]\n",
      "[Epoch 537/5000] [Batch 0/1] [D loss: 0.226115] [G loss: 1.194159]\n",
      "[Epoch 538/5000] [Batch 0/1] [D loss: 0.220863] [G loss: 1.082757]\n",
      "[Epoch 539/5000] [Batch 0/1] [D loss: 0.206809] [G loss: 1.232042]\n",
      "[Epoch 540/5000] [Batch 0/1] [D loss: 0.193315] [G loss: 1.195375]\n",
      "[Epoch 541/5000] [Batch 0/1] [D loss: 0.185359] [G loss: 1.364788]\n",
      "[Epoch 542/5000] [Batch 0/1] [D loss: 0.190742] [G loss: 1.175571]\n",
      "[Epoch 543/5000] [Batch 0/1] [D loss: 0.210193] [G loss: 1.402772]\n",
      "[Epoch 544/5000] [Batch 0/1] [D loss: 0.286654] [G loss: 0.832129]\n",
      "[Epoch 545/5000] [Batch 0/1] [D loss: 0.233749] [G loss: 1.228376]\n",
      "[Epoch 546/5000] [Batch 0/1] [D loss: 0.256553] [G loss: 0.939151]\n",
      "[Epoch 547/5000] [Batch 0/1] [D loss: 0.283819] [G loss: 1.282927]\n",
      "[Epoch 548/5000] [Batch 0/1] [D loss: 0.318024] [G loss: 0.756062]\n",
      "[Epoch 549/5000] [Batch 0/1] [D loss: 0.226661] [G loss: 1.244070]\n",
      "[Epoch 550/5000] [Batch 0/1] [D loss: 0.217771] [G loss: 1.141842]\n",
      "[Epoch 551/5000] [Batch 0/1] [D loss: 0.220377] [G loss: 1.180308]\n",
      "[Epoch 552/5000] [Batch 0/1] [D loss: 0.224858] [G loss: 1.089734]\n",
      "[Epoch 553/5000] [Batch 0/1] [D loss: 0.247521] [G loss: 1.217973]\n",
      "[Epoch 554/5000] [Batch 0/1] [D loss: 0.307965] [G loss: 0.779422]\n",
      "[Epoch 555/5000] [Batch 0/1] [D loss: 0.242748] [G loss: 1.189671]\n",
      "[Epoch 556/5000] [Batch 0/1] [D loss: 0.222008] [G loss: 1.049683]\n",
      "[Epoch 557/5000] [Batch 0/1] [D loss: 0.217939] [G loss: 1.431634]\n",
      "[Epoch 558/5000] [Batch 0/1] [D loss: 0.240604] [G loss: 0.964647]\n",
      "[Epoch 559/5000] [Batch 0/1] [D loss: 0.163482] [G loss: 1.345606]\n",
      "[Epoch 560/5000] [Batch 0/1] [D loss: 0.235100] [G loss: 1.770477]\n",
      "[Epoch 561/5000] [Batch 0/1] [D loss: 0.291386] [G loss: 0.819418]\n",
      "[Epoch 562/5000] [Batch 0/1] [D loss: 0.223625] [G loss: 1.025009]\n",
      "[Epoch 563/5000] [Batch 0/1] [D loss: 0.305352] [G loss: 1.821148]\n",
      "[Epoch 564/5000] [Batch 0/1] [D loss: 0.258570] [G loss: 0.912020]\n",
      "[Epoch 565/5000] [Batch 0/1] [D loss: 0.198359] [G loss: 1.240356]\n",
      "[Epoch 566/5000] [Batch 0/1] [D loss: 0.224871] [G loss: 1.463394]\n",
      "[Epoch 567/5000] [Batch 0/1] [D loss: 0.289679] [G loss: 0.823758]\n",
      "[Epoch 568/5000] [Batch 0/1] [D loss: 0.213015] [G loss: 1.276740]\n",
      "[Epoch 569/5000] [Batch 0/1] [D loss: 0.224847] [G loss: 1.181504]\n",
      "[Epoch 570/5000] [Batch 0/1] [D loss: 0.248690] [G loss: 0.979246]\n",
      "[Epoch 571/5000] [Batch 0/1] [D loss: 0.280558] [G loss: 1.249573]\n",
      "[Epoch 572/5000] [Batch 0/1] [D loss: 0.295827] [G loss: 0.812917]\n",
      "[Epoch 573/5000] [Batch 0/1] [D loss: 0.239757] [G loss: 1.279903]\n",
      "[Epoch 574/5000] [Batch 0/1] [D loss: 0.223562] [G loss: 1.042560]\n",
      "[Epoch 575/5000] [Batch 0/1] [D loss: 0.228809] [G loss: 1.385772]\n",
      "[Epoch 576/5000] [Batch 0/1] [D loss: 0.275769] [G loss: 0.861931]\n",
      "[Epoch 577/5000] [Batch 0/1] [D loss: 0.226436] [G loss: 1.283437]\n",
      "[Epoch 578/5000] [Batch 0/1] [D loss: 0.244498] [G loss: 0.990298]\n",
      "[Epoch 579/5000] [Batch 0/1] [D loss: 0.266049] [G loss: 1.275706]\n",
      "[Epoch 580/5000] [Batch 0/1] [D loss: 0.320588] [G loss: 0.754696]\n",
      "[Epoch 581/5000] [Batch 0/1] [D loss: 0.296739] [G loss: 1.349250]\n",
      "[Epoch 582/5000] [Batch 0/1] [D loss: 0.248993] [G loss: 0.962502]\n",
      "[Epoch 583/5000] [Batch 0/1] [D loss: 0.204345] [G loss: 1.424163]\n",
      "[Epoch 584/5000] [Batch 0/1] [D loss: 0.172804] [G loss: 1.269102]\n",
      "[Epoch 585/5000] [Batch 0/1] [D loss: 0.166008] [G loss: 1.588354]\n",
      "[Epoch 586/5000] [Batch 0/1] [D loss: 0.183971] [G loss: 1.199097]\n",
      "[Epoch 587/5000] [Batch 0/1] [D loss: 0.191515] [G loss: 1.479811]\n",
      "[Epoch 588/5000] [Batch 0/1] [D loss: 0.216419] [G loss: 1.051155]\n",
      "[Epoch 589/5000] [Batch 0/1] [D loss: 0.168694] [G loss: 1.368686]\n",
      "[Epoch 590/5000] [Batch 0/1] [D loss: 0.188323] [G loss: 1.478979]\n",
      "[Epoch 591/5000] [Batch 0/1] [D loss: 0.248123] [G loss: 0.941422]\n",
      "[Epoch 592/5000] [Batch 0/1] [D loss: 0.193594] [G loss: 1.188901]\n",
      "[Epoch 593/5000] [Batch 0/1] [D loss: 0.283799] [G loss: 1.575679]\n",
      "[Epoch 594/5000] [Batch 0/1] [D loss: 0.322845] [G loss: 0.745285]\n",
      "[Epoch 595/5000] [Batch 0/1] [D loss: 0.242212] [G loss: 0.975643]\n",
      "[Epoch 596/5000] [Batch 0/1] [D loss: 0.343494] [G loss: 1.553410]\n",
      "[Epoch 597/5000] [Batch 0/1] [D loss: 0.249078] [G loss: 0.961775]\n",
      "[Epoch 598/5000] [Batch 0/1] [D loss: 0.231488] [G loss: 1.064437]\n",
      "[Epoch 599/5000] [Batch 0/1] [D loss: 0.249516] [G loss: 1.298491]\n",
      "[Epoch 600/5000] [Batch 0/1] [D loss: 0.263713] [G loss: 0.904855]\n",
      "[Epoch 601/5000] [Batch 0/1] [D loss: 0.237207] [G loss: 1.284309]\n",
      "[Epoch 602/5000] [Batch 0/1] [D loss: 0.229452] [G loss: 1.049124]\n",
      "[Epoch 603/5000] [Batch 0/1] [D loss: 0.233225] [G loss: 1.302343]\n",
      "[Epoch 604/5000] [Batch 0/1] [D loss: 0.250085] [G loss: 0.948419]\n",
      "[Epoch 605/5000] [Batch 0/1] [D loss: 0.246330] [G loss: 1.357895]\n",
      "[Epoch 606/5000] [Batch 0/1] [D loss: 0.249153] [G loss: 0.946199]\n",
      "[Epoch 607/5000] [Batch 0/1] [D loss: 0.221643] [G loss: 1.438952]\n",
      "[Epoch 608/5000] [Batch 0/1] [D loss: 0.230259] [G loss: 1.006089]\n",
      "[Epoch 609/5000] [Batch 0/1] [D loss: 0.196632] [G loss: 1.430140]\n",
      "[Epoch 610/5000] [Batch 0/1] [D loss: 0.194406] [G loss: 1.170077]\n",
      "[Epoch 611/5000] [Batch 0/1] [D loss: 0.198211] [G loss: 1.476649]\n",
      "[Epoch 612/5000] [Batch 0/1] [D loss: 0.234725] [G loss: 0.987595]\n",
      "[Epoch 613/5000] [Batch 0/1] [D loss: 0.210128] [G loss: 1.419613]\n",
      "[Epoch 614/5000] [Batch 0/1] [D loss: 0.233298] [G loss: 0.997020]\n",
      "[Epoch 615/5000] [Batch 0/1] [D loss: 0.239372] [G loss: 1.445811]\n",
      "[Epoch 616/5000] [Batch 0/1] [D loss: 0.285117] [G loss: 0.836331]\n",
      "[Epoch 617/5000] [Batch 0/1] [D loss: 0.226644] [G loss: 1.285941]\n",
      "[Epoch 618/5000] [Batch 0/1] [D loss: 0.220948] [G loss: 1.082787]\n",
      "[Epoch 619/5000] [Batch 0/1] [D loss: 0.222133] [G loss: 1.355762]\n",
      "[Epoch 620/5000] [Batch 0/1] [D loss: 0.237860] [G loss: 0.983818]\n",
      "[Epoch 621/5000] [Batch 0/1] [D loss: 0.216691] [G loss: 1.425534]\n",
      "[Epoch 622/5000] [Batch 0/1] [D loss: 0.220779] [G loss: 1.046312]\n",
      "[Epoch 623/5000] [Batch 0/1] [D loss: 0.200077] [G loss: 1.403024]\n",
      "[Epoch 624/5000] [Batch 0/1] [D loss: 0.198581] [G loss: 1.151649]\n",
      "[Epoch 625/5000] [Batch 0/1] [D loss: 0.207338] [G loss: 1.441894]\n",
      "[Epoch 626/5000] [Batch 0/1] [D loss: 0.239254] [G loss: 0.972525]\n",
      "[Epoch 627/5000] [Batch 0/1] [D loss: 0.207115] [G loss: 1.369437]\n",
      "[Epoch 628/5000] [Batch 0/1] [D loss: 0.221718] [G loss: 1.054606]\n",
      "[Epoch 629/5000] [Batch 0/1] [D loss: 0.246639] [G loss: 1.363711]\n",
      "[Epoch 630/5000] [Batch 0/1] [D loss: 0.299789] [G loss: 0.801407]\n",
      "[Epoch 631/5000] [Batch 0/1] [D loss: 0.263802] [G loss: 1.249877]\n",
      "[Epoch 632/5000] [Batch 0/1] [D loss: 0.274752] [G loss: 0.891694]\n",
      "[Epoch 633/5000] [Batch 0/1] [D loss: 0.290362] [G loss: 1.252873]\n",
      "[Epoch 634/5000] [Batch 0/1] [D loss: 0.291049] [G loss: 0.839595]\n",
      "[Epoch 635/5000] [Batch 0/1] [D loss: 0.278630] [G loss: 1.430164]\n",
      "[Epoch 636/5000] [Batch 0/1] [D loss: 0.232481] [G loss: 1.017554]\n",
      "[Epoch 637/5000] [Batch 0/1] [D loss: 0.213957] [G loss: 1.612299]\n",
      "[Epoch 638/5000] [Batch 0/1] [D loss: 0.203640] [G loss: 1.109459]\n",
      "[Epoch 639/5000] [Batch 0/1] [D loss: 0.205810] [G loss: 1.704202]\n",
      "[Epoch 640/5000] [Batch 0/1] [D loss: 0.252333] [G loss: 0.929085]\n",
      "[Epoch 641/5000] [Batch 0/1] [D loss: 0.198687] [G loss: 1.416059]\n",
      "[Epoch 642/5000] [Batch 0/1] [D loss: 0.208576] [G loss: 1.141095]\n",
      "[Epoch 643/5000] [Batch 0/1] [D loss: 0.221607] [G loss: 1.322271]\n",
      "[Epoch 644/5000] [Batch 0/1] [D loss: 0.253152] [G loss: 0.933563]\n",
      "[Epoch 645/5000] [Batch 0/1] [D loss: 0.253581] [G loss: 1.474616]\n",
      "[Epoch 646/5000] [Batch 0/1] [D loss: 0.254993] [G loss: 0.922361]\n",
      "[Epoch 647/5000] [Batch 0/1] [D loss: 0.191827] [G loss: 1.341938]\n",
      "[Epoch 648/5000] [Batch 0/1] [D loss: 0.188313] [G loss: 1.361788]\n",
      "[Epoch 649/5000] [Batch 0/1] [D loss: 0.199551] [G loss: 1.149032]\n",
      "[Epoch 650/5000] [Batch 0/1] [D loss: 0.213430] [G loss: 1.506154]\n",
      "[Epoch 651/5000] [Batch 0/1] [D loss: 0.233893] [G loss: 0.992920]\n",
      "[Epoch 652/5000] [Batch 0/1] [D loss: 0.191345] [G loss: 1.488911]\n",
      "[Epoch 653/5000] [Batch 0/1] [D loss: 0.183527] [G loss: 1.235685]\n",
      "[Epoch 654/5000] [Batch 0/1] [D loss: 0.188601] [G loss: 1.563134]\n",
      "[Epoch 655/5000] [Batch 0/1] [D loss: 0.214031] [G loss: 1.064986]\n",
      "[Epoch 656/5000] [Batch 0/1] [D loss: 0.211182] [G loss: 1.630919]\n",
      "[Epoch 657/5000] [Batch 0/1] [D loss: 0.244153] [G loss: 0.957200]\n",
      "[Epoch 658/5000] [Batch 0/1] [D loss: 0.221454] [G loss: 1.465708]\n",
      "[Epoch 659/5000] [Batch 0/1] [D loss: 0.249710] [G loss: 0.955471]\n",
      "[Epoch 660/5000] [Batch 0/1] [D loss: 0.274626] [G loss: 1.332420]\n",
      "[Epoch 661/5000] [Batch 0/1] [D loss: 0.286714] [G loss: 0.852839]\n",
      "[Epoch 662/5000] [Batch 0/1] [D loss: 0.302206] [G loss: 1.355775]\n",
      "[Epoch 663/5000] [Batch 0/1] [D loss: 0.269781] [G loss: 0.901196]\n",
      "[Epoch 664/5000] [Batch 0/1] [D loss: 0.241500] [G loss: 1.541267]\n",
      "[Epoch 665/5000] [Batch 0/1] [D loss: 0.240604] [G loss: 0.967684]\n",
      "[Epoch 666/5000] [Batch 0/1] [D loss: 0.180616] [G loss: 1.674030]\n",
      "[Epoch 667/5000] [Batch 0/1] [D loss: 0.184238] [G loss: 1.195971]\n",
      "[Epoch 668/5000] [Batch 0/1] [D loss: 0.226338] [G loss: 1.896266]\n",
      "[Epoch 669/5000] [Batch 0/1] [D loss: 0.331183] [G loss: 0.726915]\n",
      "[Epoch 670/5000] [Batch 0/1] [D loss: 0.197864] [G loss: 1.700580]\n",
      "[Epoch 671/5000] [Batch 0/1] [D loss: 0.169952] [G loss: 1.282595]\n",
      "[Epoch 672/5000] [Batch 0/1] [D loss: 0.198430] [G loss: 1.906574]\n",
      "[Epoch 673/5000] [Batch 0/1] [D loss: 0.312300] [G loss: 0.767765]\n",
      "[Epoch 674/5000] [Batch 0/1] [D loss: 0.213336] [G loss: 1.350753]\n",
      "[Epoch 675/5000] [Batch 0/1] [D loss: 0.230534] [G loss: 1.105021]\n",
      "[Epoch 676/5000] [Batch 0/1] [D loss: 0.251902] [G loss: 1.034071]\n",
      "[Epoch 677/5000] [Batch 0/1] [D loss: 0.259900] [G loss: 1.018883]\n",
      "[Epoch 678/5000] [Batch 0/1] [D loss: 0.244761] [G loss: 1.049336]\n",
      "[Epoch 679/5000] [Batch 0/1] [D loss: 0.216266] [G loss: 1.160238]\n",
      "[Epoch 680/5000] [Batch 0/1] [D loss: 0.190014] [G loss: 1.315968]\n",
      "[Epoch 681/5000] [Batch 0/1] [D loss: 0.164059] [G loss: 1.330655]\n",
      "[Epoch 682/5000] [Batch 0/1] [D loss: 0.147886] [G loss: 1.607870]\n",
      "[Epoch 683/5000] [Batch 0/1] [D loss: 0.146100] [G loss: 1.407171]\n",
      "[Epoch 684/5000] [Batch 0/1] [D loss: 0.148946] [G loss: 1.639614]\n",
      "[Epoch 685/5000] [Batch 0/1] [D loss: 0.172159] [G loss: 1.255616]\n",
      "[Epoch 686/5000] [Batch 0/1] [D loss: 0.188206] [G loss: 1.538684]\n",
      "[Epoch 687/5000] [Batch 0/1] [D loss: 0.264244] [G loss: 0.896023]\n",
      "[Epoch 688/5000] [Batch 0/1] [D loss: 0.253853] [G loss: 1.472189]\n",
      "[Epoch 689/5000] [Batch 0/1] [D loss: 0.285420] [G loss: 0.840989]\n",
      "[Epoch 690/5000] [Batch 0/1] [D loss: 0.259905] [G loss: 1.495716]\n",
      "[Epoch 691/5000] [Batch 0/1] [D loss: 0.249059] [G loss: 0.963738]\n",
      "[Epoch 692/5000] [Batch 0/1] [D loss: 0.254399] [G loss: 1.571959]\n",
      "[Epoch 693/5000] [Batch 0/1] [D loss: 0.260294] [G loss: 0.912203]\n",
      "[Epoch 694/5000] [Batch 0/1] [D loss: 0.260570] [G loss: 1.707201]\n",
      "[Epoch 695/5000] [Batch 0/1] [D loss: 0.271444] [G loss: 0.880326]\n",
      "[Epoch 696/5000] [Batch 0/1] [D loss: 0.290162] [G loss: 1.611658]\n",
      "[Epoch 697/5000] [Batch 0/1] [D loss: 0.283288] [G loss: 0.852553]\n",
      "[Epoch 698/5000] [Batch 0/1] [D loss: 0.282727] [G loss: 1.485480]\n",
      "[Epoch 699/5000] [Batch 0/1] [D loss: 0.256143] [G loss: 0.923677]\n",
      "[Epoch 700/5000] [Batch 0/1] [D loss: 0.221594] [G loss: 1.709594]\n",
      "[Epoch 701/5000] [Batch 0/1] [D loss: 0.196785] [G loss: 1.128011]\n",
      "[Epoch 702/5000] [Batch 0/1] [D loss: 0.142365] [G loss: 1.830043]\n",
      "[Epoch 703/5000] [Batch 0/1] [D loss: 0.152528] [G loss: 1.356618]\n",
      "[Epoch 704/5000] [Batch 0/1] [D loss: 0.186750] [G loss: 1.920810]\n",
      "[Epoch 705/5000] [Batch 0/1] [D loss: 0.325652] [G loss: 0.737939]\n",
      "[Epoch 706/5000] [Batch 0/1] [D loss: 0.184160] [G loss: 1.318520]\n",
      "[Epoch 707/5000] [Batch 0/1] [D loss: 0.253572] [G loss: 1.738249]\n",
      "[Epoch 708/5000] [Batch 0/1] [D loss: 0.285890] [G loss: 0.834534]\n",
      "[Epoch 709/5000] [Batch 0/1] [D loss: 0.202930] [G loss: 1.344371]\n",
      "[Epoch 710/5000] [Batch 0/1] [D loss: 0.211805] [G loss: 1.365417]\n",
      "[Epoch 711/5000] [Batch 0/1] [D loss: 0.245296] [G loss: 0.967155]\n",
      "[Epoch 712/5000] [Batch 0/1] [D loss: 0.266345] [G loss: 1.617939]\n",
      "[Epoch 713/5000] [Batch 0/1] [D loss: 0.242259] [G loss: 0.968867]\n",
      "[Epoch 714/5000] [Batch 0/1] [D loss: 0.192659] [G loss: 1.465461]\n",
      "[Epoch 715/5000] [Batch 0/1] [D loss: 0.170558] [G loss: 1.346197]\n",
      "[Epoch 716/5000] [Batch 0/1] [D loss: 0.164170] [G loss: 1.501621]\n",
      "[Epoch 717/5000] [Batch 0/1] [D loss: 0.160477] [G loss: 1.362945]\n",
      "[Epoch 718/5000] [Batch 0/1] [D loss: 0.180223] [G loss: 1.645696]\n",
      "[Epoch 719/5000] [Batch 0/1] [D loss: 0.234582] [G loss: 0.985944]\n",
      "[Epoch 720/5000] [Batch 0/1] [D loss: 0.182692] [G loss: 1.499129]\n",
      "[Epoch 721/5000] [Batch 0/1] [D loss: 0.191191] [G loss: 1.198887]\n",
      "[Epoch 722/5000] [Batch 0/1] [D loss: 0.215532] [G loss: 1.506416]\n",
      "[Epoch 723/5000] [Batch 0/1] [D loss: 0.294980] [G loss: 0.811471]\n",
      "[Epoch 724/5000] [Batch 0/1] [D loss: 0.263986] [G loss: 1.535351]\n",
      "[Epoch 725/5000] [Batch 0/1] [D loss: 0.290796] [G loss: 0.826634]\n",
      "[Epoch 726/5000] [Batch 0/1] [D loss: 0.299832] [G loss: 1.461200]\n",
      "[Epoch 727/5000] [Batch 0/1] [D loss: 0.291112] [G loss: 0.844364]\n",
      "[Epoch 728/5000] [Batch 0/1] [D loss: 0.278476] [G loss: 1.466882]\n",
      "[Epoch 729/5000] [Batch 0/1] [D loss: 0.197649] [G loss: 1.162916]\n",
      "[Epoch 730/5000] [Batch 0/1] [D loss: 0.160289] [G loss: 1.905265]\n",
      "[Epoch 731/5000] [Batch 0/1] [D loss: 0.150828] [G loss: 1.385967]\n",
      "[Epoch 732/5000] [Batch 0/1] [D loss: 0.186769] [G loss: 1.794293]\n",
      "[Epoch 733/5000] [Batch 0/1] [D loss: 0.297205] [G loss: 0.805965]\n",
      "[Epoch 734/5000] [Batch 0/1] [D loss: 0.294629] [G loss: 1.718249]\n",
      "[Epoch 735/5000] [Batch 0/1] [D loss: 0.270352] [G loss: 0.888050]\n",
      "[Epoch 736/5000] [Batch 0/1] [D loss: 0.249484] [G loss: 1.537421]\n",
      "[Epoch 737/5000] [Batch 0/1] [D loss: 0.210243] [G loss: 1.080566]\n",
      "[Epoch 738/5000] [Batch 0/1] [D loss: 0.150247] [G loss: 1.800540]\n",
      "[Epoch 739/5000] [Batch 0/1] [D loss: 0.132983] [G loss: 1.491400]\n",
      "[Epoch 740/5000] [Batch 0/1] [D loss: 0.131751] [G loss: 1.927983]\n",
      "[Epoch 741/5000] [Batch 0/1] [D loss: 0.164129] [G loss: 1.280418]\n",
      "[Epoch 742/5000] [Batch 0/1] [D loss: 0.155948] [G loss: 1.802263]\n",
      "[Epoch 743/5000] [Batch 0/1] [D loss: 0.229834] [G loss: 1.002456]\n",
      "[Epoch 744/5000] [Batch 0/1] [D loss: 0.237213] [G loss: 1.542317]\n",
      "[Epoch 745/5000] [Batch 0/1] [D loss: 0.313529] [G loss: 0.766835]\n",
      "[Epoch 746/5000] [Batch 0/1] [D loss: 0.246089] [G loss: 1.180245]\n",
      "[Epoch 747/5000] [Batch 0/1] [D loss: 0.226186] [G loss: 1.169920]\n",
      "[Epoch 748/5000] [Batch 0/1] [D loss: 0.211631] [G loss: 1.168075]\n",
      "[Epoch 749/5000] [Batch 0/1] [D loss: 0.197490] [G loss: 1.476238]\n",
      "[Epoch 750/5000] [Batch 0/1] [D loss: 0.189546] [G loss: 1.179562]\n",
      "[Epoch 751/5000] [Batch 0/1] [D loss: 0.189722] [G loss: 1.859969]\n",
      "[Epoch 752/5000] [Batch 0/1] [D loss: 0.226083] [G loss: 1.015929]\n",
      "[Epoch 753/5000] [Batch 0/1] [D loss: 0.186669] [G loss: 1.708339]\n",
      "[Epoch 754/5000] [Batch 0/1] [D loss: 0.236745] [G loss: 0.992355]\n",
      "[Epoch 755/5000] [Batch 0/1] [D loss: 0.284407] [G loss: 1.486144]\n",
      "[Epoch 756/5000] [Batch 0/1] [D loss: 0.306333] [G loss: 0.801640]\n",
      "[Epoch 757/5000] [Batch 0/1] [D loss: 0.305130] [G loss: 1.371218]\n",
      "[Epoch 758/5000] [Batch 0/1] [D loss: 0.231598] [G loss: 1.074719]\n",
      "[Epoch 759/5000] [Batch 0/1] [D loss: 0.175799] [G loss: 1.522631]\n",
      "[Epoch 760/5000] [Batch 0/1] [D loss: 0.155654] [G loss: 1.488597]\n",
      "[Epoch 761/5000] [Batch 0/1] [D loss: 0.150941] [G loss: 1.495299]\n",
      "[Epoch 762/5000] [Batch 0/1] [D loss: 0.151798] [G loss: 1.572548]\n",
      "[Epoch 763/5000] [Batch 0/1] [D loss: 0.166347] [G loss: 1.348878]\n",
      "[Epoch 764/5000] [Batch 0/1] [D loss: 0.207033] [G loss: 1.730719]\n",
      "[Epoch 765/5000] [Batch 0/1] [D loss: 0.303860] [G loss: 0.789559]\n",
      "[Epoch 766/5000] [Batch 0/1] [D loss: 0.226286] [G loss: 1.732191]\n",
      "[Epoch 767/5000] [Batch 0/1] [D loss: 0.196624] [G loss: 1.153816]\n",
      "[Epoch 768/5000] [Batch 0/1] [D loss: 0.198117] [G loss: 1.885840]\n",
      "[Epoch 769/5000] [Batch 0/1] [D loss: 0.195192] [G loss: 1.140309]\n",
      "[Epoch 770/5000] [Batch 0/1] [D loss: 0.162102] [G loss: 1.815459]\n",
      "[Epoch 771/5000] [Batch 0/1] [D loss: 0.183572] [G loss: 1.195994]\n",
      "[Epoch 772/5000] [Batch 0/1] [D loss: 0.217887] [G loss: 1.845668]\n",
      "[Epoch 773/5000] [Batch 0/1] [D loss: 0.280808] [G loss: 0.848127]\n",
      "[Epoch 774/5000] [Batch 0/1] [D loss: 0.216144] [G loss: 1.461830]\n",
      "[Epoch 775/5000] [Batch 0/1] [D loss: 0.222466] [G loss: 1.102101]\n",
      "[Epoch 776/5000] [Batch 0/1] [D loss: 0.238007] [G loss: 1.225916]\n",
      "[Epoch 777/5000] [Batch 0/1] [D loss: 0.255188] [G loss: 0.985614]\n",
      "[Epoch 778/5000] [Batch 0/1] [D loss: 0.265374] [G loss: 1.294191]\n",
      "[Epoch 779/5000] [Batch 0/1] [D loss: 0.272937] [G loss: 0.905268]\n",
      "[Epoch 780/5000] [Batch 0/1] [D loss: 0.244138] [G loss: 1.490730]\n",
      "[Epoch 781/5000] [Batch 0/1] [D loss: 0.203531] [G loss: 1.190804]\n",
      "[Epoch 782/5000] [Batch 0/1] [D loss: 0.184424] [G loss: 1.596708]\n",
      "[Epoch 783/5000] [Batch 0/1] [D loss: 0.173362] [G loss: 1.292190]\n",
      "[Epoch 784/5000] [Batch 0/1] [D loss: 0.191453] [G loss: 2.000085]\n",
      "[Epoch 785/5000] [Batch 0/1] [D loss: 0.241193] [G loss: 0.967549]\n",
      "[Epoch 786/5000] [Batch 0/1] [D loss: 0.263563] [G loss: 2.258436]\n",
      "[Epoch 787/5000] [Batch 0/1] [D loss: 0.249610] [G loss: 0.948040]\n",
      "[Epoch 788/5000] [Batch 0/1] [D loss: 0.270768] [G loss: 1.873433]\n",
      "[Epoch 789/5000] [Batch 0/1] [D loss: 0.260729] [G loss: 0.919318]\n",
      "[Epoch 790/5000] [Batch 0/1] [D loss: 0.225631] [G loss: 1.690651]\n",
      "[Epoch 791/5000] [Batch 0/1] [D loss: 0.182491] [G loss: 1.261839]\n",
      "[Epoch 792/5000] [Batch 0/1] [D loss: 0.159364] [G loss: 1.676591]\n",
      "[Epoch 793/5000] [Batch 0/1] [D loss: 0.150322] [G loss: 1.441758]\n",
      "[Epoch 794/5000] [Batch 0/1] [D loss: 0.162903] [G loss: 1.655072]\n",
      "[Epoch 795/5000] [Batch 0/1] [D loss: 0.200818] [G loss: 1.122812]\n",
      "[Epoch 796/5000] [Batch 0/1] [D loss: 0.208228] [G loss: 1.639631]\n",
      "[Epoch 797/5000] [Batch 0/1] [D loss: 0.228734] [G loss: 1.009581]\n",
      "[Epoch 798/5000] [Batch 0/1] [D loss: 0.194100] [G loss: 1.474846]\n",
      "[Epoch 799/5000] [Batch 0/1] [D loss: 0.199316] [G loss: 1.173098]\n",
      "[Epoch 800/5000] [Batch 0/1] [D loss: 0.207202] [G loss: 1.452539]\n",
      "[Epoch 801/5000] [Batch 0/1] [D loss: 0.224671] [G loss: 1.041291]\n",
      "[Epoch 802/5000] [Batch 0/1] [D loss: 0.241782] [G loss: 1.653843]\n",
      "[Epoch 803/5000] [Batch 0/1] [D loss: 0.225482] [G loss: 1.032486]\n",
      "[Epoch 804/5000] [Batch 0/1] [D loss: 0.185999] [G loss: 1.546313]\n",
      "[Epoch 805/5000] [Batch 0/1] [D loss: 0.167808] [G loss: 1.395979]\n",
      "[Epoch 806/5000] [Batch 0/1] [D loss: 0.170196] [G loss: 1.504363]\n",
      "[Epoch 807/5000] [Batch 0/1] [D loss: 0.181571] [G loss: 1.324098]\n",
      "[Epoch 808/5000] [Batch 0/1] [D loss: 0.195672] [G loss: 1.535577]\n",
      "[Epoch 809/5000] [Batch 0/1] [D loss: 0.237095] [G loss: 0.998057]\n",
      "[Epoch 810/5000] [Batch 0/1] [D loss: 0.307267] [G loss: 2.063046]\n",
      "[Epoch 811/5000] [Batch 0/1] [D loss: 0.257237] [G loss: 0.928320]\n",
      "[Epoch 812/5000] [Batch 0/1] [D loss: 0.244377] [G loss: 1.675969]\n",
      "[Epoch 813/5000] [Batch 0/1] [D loss: 0.230390] [G loss: 1.029259]\n",
      "[Epoch 814/5000] [Batch 0/1] [D loss: 0.213084] [G loss: 1.678204]\n",
      "[Epoch 815/5000] [Batch 0/1] [D loss: 0.193307] [G loss: 1.184264]\n",
      "[Epoch 816/5000] [Batch 0/1] [D loss: 0.201527] [G loss: 1.661097]\n",
      "[Epoch 817/5000] [Batch 0/1] [D loss: 0.218998] [G loss: 1.059461]\n",
      "[Epoch 818/5000] [Batch 0/1] [D loss: 0.221383] [G loss: 1.747726]\n",
      "[Epoch 819/5000] [Batch 0/1] [D loss: 0.219577] [G loss: 1.050623]\n",
      "[Epoch 820/5000] [Batch 0/1] [D loss: 0.212366] [G loss: 1.993934]\n",
      "[Epoch 821/5000] [Batch 0/1] [D loss: 0.237694] [G loss: 0.980267]\n",
      "[Epoch 822/5000] [Batch 0/1] [D loss: 0.285946] [G loss: 2.085772]\n",
      "[Epoch 823/5000] [Batch 0/1] [D loss: 0.324944] [G loss: 0.746862]\n",
      "[Epoch 824/5000] [Batch 0/1] [D loss: 0.346418] [G loss: 2.215267]\n",
      "[Epoch 825/5000] [Batch 0/1] [D loss: 0.200298] [G loss: 1.259596]\n",
      "[Epoch 826/5000] [Batch 0/1] [D loss: 0.137016] [G loss: 1.639315]\n",
      "[Epoch 827/5000] [Batch 0/1] [D loss: 0.130145] [G loss: 2.241585]\n",
      "[Epoch 828/5000] [Batch 0/1] [D loss: 0.202508] [G loss: 1.103595]\n",
      "[Epoch 829/5000] [Batch 0/1] [D loss: 0.200952] [G loss: 2.412624]\n",
      "[Epoch 830/5000] [Batch 0/1] [D loss: 0.261516] [G loss: 0.901756]\n",
      "[Epoch 831/5000] [Batch 0/1] [D loss: 0.213804] [G loss: 1.646033]\n",
      "[Epoch 832/5000] [Batch 0/1] [D loss: 0.215452] [G loss: 1.089067]\n",
      "[Epoch 833/5000] [Batch 0/1] [D loss: 0.217539] [G loss: 1.532821]\n",
      "[Epoch 834/5000] [Batch 0/1] [D loss: 0.203583] [G loss: 1.140026]\n",
      "[Epoch 835/5000] [Batch 0/1] [D loss: 0.187239] [G loss: 1.525594]\n",
      "[Epoch 836/5000] [Batch 0/1] [D loss: 0.197183] [G loss: 1.157268]\n",
      "[Epoch 837/5000] [Batch 0/1] [D loss: 0.209221] [G loss: 1.577829]\n",
      "[Epoch 838/5000] [Batch 0/1] [D loss: 0.225366] [G loss: 1.031088]\n",
      "[Epoch 839/5000] [Batch 0/1] [D loss: 0.195175] [G loss: 1.521344]\n",
      "[Epoch 840/5000] [Batch 0/1] [D loss: 0.184469] [G loss: 1.241639]\n",
      "[Epoch 841/5000] [Batch 0/1] [D loss: 0.188854] [G loss: 1.571240]\n",
      "[Epoch 842/5000] [Batch 0/1] [D loss: 0.209214] [G loss: 1.118669]\n",
      "[Epoch 843/5000] [Batch 0/1] [D loss: 0.246781] [G loss: 1.629594]\n",
      "[Epoch 844/5000] [Batch 0/1] [D loss: 0.264806] [G loss: 0.904707]\n",
      "[Epoch 845/5000] [Batch 0/1] [D loss: 0.249142] [G loss: 1.731570]\n",
      "[Epoch 846/5000] [Batch 0/1] [D loss: 0.198966] [G loss: 1.175292]\n",
      "[Epoch 847/5000] [Batch 0/1] [D loss: 0.181543] [G loss: 1.828611]\n",
      "[Epoch 848/5000] [Batch 0/1] [D loss: 0.172294] [G loss: 1.270538]\n",
      "[Epoch 849/5000] [Batch 0/1] [D loss: 0.190500] [G loss: 2.187944]\n",
      "[Epoch 850/5000] [Batch 0/1] [D loss: 0.212426] [G loss: 1.071457]\n",
      "[Epoch 851/5000] [Batch 0/1] [D loss: 0.209385] [G loss: 2.096990]\n",
      "[Epoch 852/5000] [Batch 0/1] [D loss: 0.205245] [G loss: 1.110756]\n",
      "[Epoch 853/5000] [Batch 0/1] [D loss: 0.201333] [G loss: 1.697693]\n",
      "[Epoch 854/5000] [Batch 0/1] [D loss: 0.202689] [G loss: 1.150796]\n",
      "[Epoch 855/5000] [Batch 0/1] [D loss: 0.209807] [G loss: 1.525388]\n",
      "[Epoch 856/5000] [Batch 0/1] [D loss: 0.206673] [G loss: 1.144608]\n",
      "[Epoch 857/5000] [Batch 0/1] [D loss: 0.186044] [G loss: 1.614087]\n",
      "[Epoch 858/5000] [Batch 0/1] [D loss: 0.161321] [G loss: 1.357270]\n",
      "[Epoch 859/5000] [Batch 0/1] [D loss: 0.165463] [G loss: 1.756582]\n",
      "[Epoch 860/5000] [Batch 0/1] [D loss: 0.187568] [G loss: 1.173969]\n",
      "[Epoch 861/5000] [Batch 0/1] [D loss: 0.168063] [G loss: 1.915010]\n",
      "[Epoch 862/5000] [Batch 0/1] [D loss: 0.196507] [G loss: 1.132123]\n",
      "[Epoch 863/5000] [Batch 0/1] [D loss: 0.199977] [G loss: 1.870819]\n",
      "[Epoch 864/5000] [Batch 0/1] [D loss: 0.323308] [G loss: 0.745778]\n",
      "[Epoch 865/5000] [Batch 0/1] [D loss: 0.377582] [G loss: 2.212563]\n",
      "[Epoch 866/5000] [Batch 0/1] [D loss: 0.295034] [G loss: 0.853710]\n",
      "[Epoch 867/5000] [Batch 0/1] [D loss: 0.253334] [G loss: 1.420803]\n",
      "[Epoch 868/5000] [Batch 0/1] [D loss: 0.187685] [G loss: 1.287508]\n",
      "[Epoch 869/5000] [Batch 0/1] [D loss: 0.176076] [G loss: 1.951569]\n",
      "[Epoch 870/5000] [Batch 0/1] [D loss: 0.182267] [G loss: 1.212510]\n",
      "[Epoch 871/5000] [Batch 0/1] [D loss: 0.229926] [G loss: 2.514078]\n",
      "[Epoch 872/5000] [Batch 0/1] [D loss: 0.272853] [G loss: 0.871676]\n",
      "[Epoch 873/5000] [Batch 0/1] [D loss: 0.260333] [G loss: 1.940300]\n",
      "[Epoch 874/5000] [Batch 0/1] [D loss: 0.253740] [G loss: 0.954619]\n",
      "[Epoch 875/5000] [Batch 0/1] [D loss: 0.252320] [G loss: 1.444393]\n",
      "[Epoch 876/5000] [Batch 0/1] [D loss: 0.234155] [G loss: 1.054892]\n",
      "[Epoch 877/5000] [Batch 0/1] [D loss: 0.206687] [G loss: 1.375060]\n",
      "[Epoch 878/5000] [Batch 0/1] [D loss: 0.168572] [G loss: 1.365749]\n",
      "[Epoch 879/5000] [Batch 0/1] [D loss: 0.145170] [G loss: 1.696715]\n",
      "[Epoch 880/5000] [Batch 0/1] [D loss: 0.124266] [G loss: 1.601084]\n",
      "[Epoch 881/5000] [Batch 0/1] [D loss: 0.116638] [G loss: 1.883910]\n",
      "[Epoch 882/5000] [Batch 0/1] [D loss: 0.123705] [G loss: 1.620488]\n",
      "[Epoch 883/5000] [Batch 0/1] [D loss: 0.142589] [G loss: 1.792353]\n",
      "[Epoch 884/5000] [Batch 0/1] [D loss: 0.202763] [G loss: 1.116550]\n",
      "[Epoch 885/5000] [Batch 0/1] [D loss: 0.252297] [G loss: 1.902091]\n",
      "[Epoch 886/5000] [Batch 0/1] [D loss: 0.294674] [G loss: 0.818477]\n",
      "[Epoch 887/5000] [Batch 0/1] [D loss: 0.249924] [G loss: 1.574653]\n",
      "[Epoch 888/5000] [Batch 0/1] [D loss: 0.204082] [G loss: 1.206758]\n",
      "[Epoch 889/5000] [Batch 0/1] [D loss: 0.161579] [G loss: 1.590611]\n",
      "[Epoch 890/5000] [Batch 0/1] [D loss: 0.136467] [G loss: 1.578801]\n",
      "[Epoch 891/5000] [Batch 0/1] [D loss: 0.138018] [G loss: 1.829473]\n",
      "[Epoch 892/5000] [Batch 0/1] [D loss: 0.160680] [G loss: 1.332758]\n",
      "[Epoch 893/5000] [Batch 0/1] [D loss: 0.187880] [G loss: 1.887967]\n",
      "[Epoch 894/5000] [Batch 0/1] [D loss: 0.242688] [G loss: 0.965125]\n",
      "[Epoch 895/5000] [Batch 0/1] [D loss: 0.243549] [G loss: 1.778953]\n",
      "[Epoch 896/5000] [Batch 0/1] [D loss: 0.234370] [G loss: 1.022296]\n",
      "[Epoch 897/5000] [Batch 0/1] [D loss: 0.233736] [G loss: 1.450678]\n",
      "[Epoch 898/5000] [Batch 0/1] [D loss: 0.222954] [G loss: 1.095703]\n",
      "[Epoch 899/5000] [Batch 0/1] [D loss: 0.196283] [G loss: 1.464771]\n",
      "[Epoch 900/5000] [Batch 0/1] [D loss: 0.164215] [G loss: 1.430196]\n",
      "[Epoch 901/5000] [Batch 0/1] [D loss: 0.145241] [G loss: 1.692423]\n",
      "[Epoch 902/5000] [Batch 0/1] [D loss: 0.135328] [G loss: 1.621298]\n",
      "[Epoch 903/5000] [Batch 0/1] [D loss: 0.136434] [G loss: 1.739935]\n",
      "[Epoch 904/5000] [Batch 0/1] [D loss: 0.150413] [G loss: 1.468223]\n",
      "[Epoch 905/5000] [Batch 0/1] [D loss: 0.195938] [G loss: 1.845883]\n",
      "[Epoch 906/5000] [Batch 0/1] [D loss: 0.345624] [G loss: 0.699048]\n",
      "[Epoch 907/5000] [Batch 0/1] [D loss: 0.400067] [G loss: 2.772733]\n",
      "[Epoch 908/5000] [Batch 0/1] [D loss: 0.216445] [G loss: 1.304485]\n",
      "[Epoch 909/5000] [Batch 0/1] [D loss: 0.294725] [G loss: 0.825633]\n",
      "[Epoch 910/5000] [Batch 0/1] [D loss: 0.286774] [G loss: 1.926807]\n",
      "[Epoch 911/5000] [Batch 0/1] [D loss: 0.198740] [G loss: 1.475416]\n",
      "[Epoch 912/5000] [Batch 0/1] [D loss: 0.180096] [G loss: 1.268056]\n",
      "[Epoch 913/5000] [Batch 0/1] [D loss: 0.177545] [G loss: 1.915465]\n",
      "[Epoch 914/5000] [Batch 0/1] [D loss: 0.167128] [G loss: 1.342393]\n",
      "[Epoch 915/5000] [Batch 0/1] [D loss: 0.167101] [G loss: 1.569099]\n",
      "[Epoch 916/5000] [Batch 0/1] [D loss: 0.176023] [G loss: 1.371167]\n",
      "[Epoch 917/5000] [Batch 0/1] [D loss: 0.187457] [G loss: 1.500935]\n",
      "[Epoch 918/5000] [Batch 0/1] [D loss: 0.198039] [G loss: 1.193349]\n",
      "[Epoch 919/5000] [Batch 0/1] [D loss: 0.221472] [G loss: 1.734622]\n",
      "[Epoch 920/5000] [Batch 0/1] [D loss: 0.201744] [G loss: 1.115480]\n",
      "[Epoch 921/5000] [Batch 0/1] [D loss: 0.136176] [G loss: 1.982935]\n",
      "[Epoch 922/5000] [Batch 0/1] [D loss: 0.121072] [G loss: 1.629616]\n",
      "[Epoch 923/5000] [Batch 0/1] [D loss: 0.135454] [G loss: 1.966477]\n",
      "[Epoch 924/5000] [Batch 0/1] [D loss: 0.192809] [G loss: 1.148091]\n",
      "[Epoch 925/5000] [Batch 0/1] [D loss: 0.202509] [G loss: 2.096059]\n",
      "[Epoch 926/5000] [Batch 0/1] [D loss: 0.257376] [G loss: 0.916581]\n",
      "[Epoch 927/5000] [Batch 0/1] [D loss: 0.251888] [G loss: 1.815255]\n",
      "[Epoch 928/5000] [Batch 0/1] [D loss: 0.244604] [G loss: 0.992084]\n",
      "[Epoch 929/5000] [Batch 0/1] [D loss: 0.240923] [G loss: 1.505673]\n",
      "[Epoch 930/5000] [Batch 0/1] [D loss: 0.217007] [G loss: 1.135665]\n",
      "[Epoch 931/5000] [Batch 0/1] [D loss: 0.180385] [G loss: 1.644873]\n",
      "[Epoch 932/5000] [Batch 0/1] [D loss: 0.158579] [G loss: 1.444464]\n",
      "[Epoch 933/5000] [Batch 0/1] [D loss: 0.145061] [G loss: 1.762638]\n",
      "[Epoch 934/5000] [Batch 0/1] [D loss: 0.141768] [G loss: 1.479034]\n",
      "[Epoch 935/5000] [Batch 0/1] [D loss: 0.157061] [G loss: 2.167314]\n",
      "[Epoch 936/5000] [Batch 0/1] [D loss: 0.215078] [G loss: 1.056051]\n",
      "[Epoch 937/5000] [Batch 0/1] [D loss: 0.184425] [G loss: 2.188423]\n",
      "[Epoch 938/5000] [Batch 0/1] [D loss: 0.199777] [G loss: 1.123627]\n",
      "[Epoch 939/5000] [Batch 0/1] [D loss: 0.201636] [G loss: 2.022818]\n",
      "[Epoch 940/5000] [Batch 0/1] [D loss: 0.238383] [G loss: 0.980611]\n",
      "[Epoch 941/5000] [Batch 0/1] [D loss: 0.216620] [G loss: 1.801617]\n",
      "[Epoch 942/5000] [Batch 0/1] [D loss: 0.206447] [G loss: 1.156126]\n",
      "[Epoch 943/5000] [Batch 0/1] [D loss: 0.210849] [G loss: 1.480171]\n",
      "[Epoch 944/5000] [Batch 0/1] [D loss: 0.212251] [G loss: 1.185385]\n",
      "[Epoch 945/5000] [Batch 0/1] [D loss: 0.210605] [G loss: 1.331297]\n",
      "[Epoch 946/5000] [Batch 0/1] [D loss: 0.206866] [G loss: 1.266781]\n",
      "[Epoch 947/5000] [Batch 0/1] [D loss: 0.201636] [G loss: 1.412087]\n",
      "[Epoch 948/5000] [Batch 0/1] [D loss: 0.190923] [G loss: 1.286838]\n",
      "[Epoch 949/5000] [Batch 0/1] [D loss: 0.179985] [G loss: 1.564653]\n",
      "[Epoch 950/5000] [Batch 0/1] [D loss: 0.170530] [G loss: 1.450987]\n",
      "[Epoch 951/5000] [Batch 0/1] [D loss: 0.166801] [G loss: 1.577440]\n",
      "[Epoch 952/5000] [Batch 0/1] [D loss: 0.165477] [G loss: 1.469830]\n",
      "[Epoch 953/5000] [Batch 0/1] [D loss: 0.164385] [G loss: 1.649469]\n",
      "[Epoch 954/5000] [Batch 0/1] [D loss: 0.163545] [G loss: 1.391724]\n",
      "[Epoch 955/5000] [Batch 0/1] [D loss: 0.186477] [G loss: 2.178239]\n",
      "[Epoch 956/5000] [Batch 0/1] [D loss: 0.236651] [G loss: 0.988432]\n",
      "[Epoch 957/5000] [Batch 0/1] [D loss: 0.201836] [G loss: 2.377003]\n",
      "[Epoch 958/5000] [Batch 0/1] [D loss: 0.143013] [G loss: 1.518921]\n",
      "[Epoch 959/5000] [Batch 0/1] [D loss: 0.134599] [G loss: 1.716494]\n",
      "[Epoch 960/5000] [Batch 0/1] [D loss: 0.144243] [G loss: 1.727063]\n",
      "[Epoch 961/5000] [Batch 0/1] [D loss: 0.161050] [G loss: 1.396781]\n",
      "[Epoch 962/5000] [Batch 0/1] [D loss: 0.187720] [G loss: 1.800167]\n",
      "[Epoch 963/5000] [Batch 0/1] [D loss: 0.235578] [G loss: 1.001298]\n",
      "[Epoch 964/5000] [Batch 0/1] [D loss: 0.249760] [G loss: 1.904661]\n",
      "[Epoch 965/5000] [Batch 0/1] [D loss: 0.209561] [G loss: 1.184198]\n",
      "[Epoch 966/5000] [Batch 0/1] [D loss: 0.207171] [G loss: 1.359766]\n",
      "[Epoch 967/5000] [Batch 0/1] [D loss: 0.202840] [G loss: 1.340032]\n",
      "[Epoch 968/5000] [Batch 0/1] [D loss: 0.194795] [G loss: 1.352065]\n",
      "[Epoch 969/5000] [Batch 0/1] [D loss: 0.177637] [G loss: 1.630689]\n",
      "[Epoch 970/5000] [Batch 0/1] [D loss: 0.165285] [G loss: 1.341259]\n",
      "[Epoch 971/5000] [Batch 0/1] [D loss: 0.223299] [G loss: 2.563735]\n",
      "[Epoch 972/5000] [Batch 0/1] [D loss: 0.254179] [G loss: 0.925011]\n",
      "[Epoch 973/5000] [Batch 0/1] [D loss: 0.170251] [G loss: 2.342840]\n",
      "[Epoch 974/5000] [Batch 0/1] [D loss: 0.154441] [G loss: 1.390015]\n",
      "[Epoch 975/5000] [Batch 0/1] [D loss: 0.172266] [G loss: 2.067863]\n",
      "[Epoch 976/5000] [Batch 0/1] [D loss: 0.230983] [G loss: 1.016094]\n",
      "[Epoch 977/5000] [Batch 0/1] [D loss: 0.282424] [G loss: 2.291501]\n",
      "[Epoch 978/5000] [Batch 0/1] [D loss: 0.203595] [G loss: 1.239292]\n",
      "[Epoch 979/5000] [Batch 0/1] [D loss: 0.175808] [G loss: 1.543926]\n",
      "[Epoch 980/5000] [Batch 0/1] [D loss: 0.170739] [G loss: 1.584815]\n",
      "[Epoch 981/5000] [Batch 0/1] [D loss: 0.167811] [G loss: 1.370051]\n",
      "[Epoch 982/5000] [Batch 0/1] [D loss: 0.190672] [G loss: 1.873384]\n",
      "[Epoch 983/5000] [Batch 0/1] [D loss: 0.202678] [G loss: 1.127389]\n",
      "[Epoch 984/5000] [Batch 0/1] [D loss: 0.202763] [G loss: 2.040934]\n",
      "[Epoch 985/5000] [Batch 0/1] [D loss: 0.170688] [G loss: 1.326475]\n",
      "[Epoch 986/5000] [Batch 0/1] [D loss: 0.166542] [G loss: 1.723905]\n",
      "[Epoch 987/5000] [Batch 0/1] [D loss: 0.168957] [G loss: 1.350202]\n",
      "[Epoch 988/5000] [Batch 0/1] [D loss: 0.187650] [G loss: 1.909015]\n",
      "[Epoch 989/5000] [Batch 0/1] [D loss: 0.230203] [G loss: 1.015740]\n",
      "[Epoch 990/5000] [Batch 0/1] [D loss: 0.261138] [G loss: 2.294411]\n",
      "[Epoch 991/5000] [Batch 0/1] [D loss: 0.184995] [G loss: 1.261247]\n",
      "[Epoch 992/5000] [Batch 0/1] [D loss: 0.149927] [G loss: 1.743891]\n",
      "[Epoch 993/5000] [Batch 0/1] [D loss: 0.145018] [G loss: 1.649957]\n",
      "[Epoch 994/5000] [Batch 0/1] [D loss: 0.148314] [G loss: 1.585315]\n",
      "[Epoch 995/5000] [Batch 0/1] [D loss: 0.163427] [G loss: 1.687451]\n",
      "[Epoch 996/5000] [Batch 0/1] [D loss: 0.201509] [G loss: 1.182677]\n",
      "[Epoch 997/5000] [Batch 0/1] [D loss: 0.291356] [G loss: 2.172240]\n",
      "[Epoch 998/5000] [Batch 0/1] [D loss: 0.289252] [G loss: 0.869248]\n",
      "[Epoch 999/5000] [Batch 0/1] [D loss: 0.273006] [G loss: 1.786845]\n",
      "[Epoch 1000/5000] [Batch 0/1] [D loss: 0.211139] [G loss: 1.293912]\n",
      "[Epoch 1001/5000] [Batch 0/1] [D loss: 0.159380] [G loss: 1.550577]\n",
      "[Epoch 1002/5000] [Batch 0/1] [D loss: 0.124217] [G loss: 2.105495]\n",
      "[Epoch 1003/5000] [Batch 0/1] [D loss: 0.120240] [G loss: 1.608367]\n",
      "[Epoch 1004/5000] [Batch 0/1] [D loss: 0.155458] [G loss: 2.419840]\n",
      "[Epoch 1005/5000] [Batch 0/1] [D loss: 0.248858] [G loss: 0.940736]\n",
      "[Epoch 1006/5000] [Batch 0/1] [D loss: 0.215567] [G loss: 2.402222]\n",
      "[Epoch 1007/5000] [Batch 0/1] [D loss: 0.199404] [G loss: 1.135516]\n",
      "[Epoch 1008/5000] [Batch 0/1] [D loss: 0.214622] [G loss: 1.810134]\n",
      "[Epoch 1009/5000] [Batch 0/1] [D loss: 0.238429] [G loss: 0.997392]\n",
      "[Epoch 1010/5000] [Batch 0/1] [D loss: 0.241644] [G loss: 1.766405]\n",
      "[Epoch 1011/5000] [Batch 0/1] [D loss: 0.213258] [G loss: 1.153211]\n",
      "[Epoch 1012/5000] [Batch 0/1] [D loss: 0.196125] [G loss: 1.513644]\n",
      "[Epoch 1013/5000] [Batch 0/1] [D loss: 0.166701] [G loss: 1.502099]\n",
      "[Epoch 1014/5000] [Batch 0/1] [D loss: 0.133612] [G loss: 1.759269]\n",
      "[Epoch 1015/5000] [Batch 0/1] [D loss: 0.115292] [G loss: 1.875792]\n",
      "[Epoch 1016/5000] [Batch 0/1] [D loss: 0.115414] [G loss: 1.778854]\n",
      "[Epoch 1017/5000] [Batch 0/1] [D loss: 0.136942] [G loss: 1.927869]\n",
      "[Epoch 1018/5000] [Batch 0/1] [D loss: 0.215456] [G loss: 1.075856]\n",
      "[Epoch 1019/5000] [Batch 0/1] [D loss: 0.408387] [G loss: 2.942889]\n",
      "[Epoch 1020/5000] [Batch 0/1] [D loss: 0.272890] [G loss: 0.944095]\n",
      "[Epoch 1021/5000] [Batch 0/1] [D loss: 0.277111] [G loss: 1.474721]\n",
      "[Epoch 1022/5000] [Batch 0/1] [D loss: 0.267804] [G loss: 1.100355]\n",
      "[Epoch 1023/5000] [Batch 0/1] [D loss: 0.203357] [G loss: 1.520233]\n",
      "[Epoch 1024/5000] [Batch 0/1] [D loss: 0.127814] [G loss: 1.774732]\n",
      "[Epoch 1025/5000] [Batch 0/1] [D loss: 0.090769] [G loss: 2.229960]\n",
      "[Epoch 1026/5000] [Batch 0/1] [D loss: 0.088372] [G loss: 1.995744]\n",
      "[Epoch 1027/5000] [Batch 0/1] [D loss: 0.096595] [G loss: 2.203720]\n",
      "[Epoch 1028/5000] [Batch 0/1] [D loss: 0.152200] [G loss: 1.356979]\n",
      "[Epoch 1029/5000] [Batch 0/1] [D loss: 0.343080] [G loss: 2.991583]\n",
      "[Epoch 1030/5000] [Batch 0/1] [D loss: 0.360053] [G loss: 0.669566]\n",
      "[Epoch 1031/5000] [Batch 0/1] [D loss: 0.252903] [G loss: 1.960810]\n",
      "[Epoch 1032/5000] [Batch 0/1] [D loss: 0.203779] [G loss: 1.295280]\n",
      "[Epoch 1033/5000] [Batch 0/1] [D loss: 0.215002] [G loss: 1.190425]\n",
      "[Epoch 1034/5000] [Batch 0/1] [D loss: 0.231708] [G loss: 1.630582]\n",
      "[Epoch 1035/5000] [Batch 0/1] [D loss: 0.226611] [G loss: 1.033031]\n",
      "[Epoch 1036/5000] [Batch 0/1] [D loss: 0.240911] [G loss: 2.337510]\n",
      "[Epoch 1037/5000] [Batch 0/1] [D loss: 0.166640] [G loss: 1.278307]\n",
      "[Epoch 1038/5000] [Batch 0/1] [D loss: 0.108876] [G loss: 2.273721]\n",
      "[Epoch 1039/5000] [Batch 0/1] [D loss: 0.097223] [G loss: 1.814956]\n",
      "[Epoch 1040/5000] [Batch 0/1] [D loss: 0.103421] [G loss: 2.101575]\n",
      "[Epoch 1041/5000] [Batch 0/1] [D loss: 0.141357] [G loss: 1.437786]\n",
      "[Epoch 1042/5000] [Batch 0/1] [D loss: 0.238753] [G loss: 2.283954]\n",
      "[Epoch 1043/5000] [Batch 0/1] [D loss: 0.371847] [G loss: 0.647860]\n",
      "[Epoch 1044/5000] [Batch 0/1] [D loss: 0.203607] [G loss: 1.553773]\n",
      "[Epoch 1045/5000] [Batch 0/1] [D loss: 0.195826] [G loss: 1.546003]\n",
      "[Epoch 1046/5000] [Batch 0/1] [D loss: 0.192562] [G loss: 1.197126]\n",
      "[Epoch 1047/5000] [Batch 0/1] [D loss: 0.173430] [G loss: 1.667122]\n",
      "[Epoch 1048/5000] [Batch 0/1] [D loss: 0.162777] [G loss: 1.410085]\n",
      "[Epoch 1049/5000] [Batch 0/1] [D loss: 0.154229] [G loss: 1.606065]\n",
      "[Epoch 1050/5000] [Batch 0/1] [D loss: 0.151623] [G loss: 1.533971]\n",
      "[Epoch 1051/5000] [Batch 0/1] [D loss: 0.146247] [G loss: 1.677545]\n",
      "[Epoch 1052/5000] [Batch 0/1] [D loss: 0.142039] [G loss: 1.549016]\n",
      "[Epoch 1053/5000] [Batch 0/1] [D loss: 0.150300] [G loss: 1.919295]\n",
      "[Epoch 1054/5000] [Batch 0/1] [D loss: 0.207604] [G loss: 1.098245]\n",
      "[Epoch 1055/5000] [Batch 0/1] [D loss: 0.295816] [G loss: 2.769809]\n",
      "[Epoch 1056/5000] [Batch 0/1] [D loss: 0.172547] [G loss: 1.385190]\n",
      "[Epoch 1057/5000] [Batch 0/1] [D loss: 0.184178] [G loss: 1.306171]\n",
      "[Epoch 1058/5000] [Batch 0/1] [D loss: 0.208402] [G loss: 1.758722]\n",
      "[Epoch 1059/5000] [Batch 0/1] [D loss: 0.207034] [G loss: 1.186307]\n",
      "[Epoch 1060/5000] [Batch 0/1] [D loss: 0.199389] [G loss: 1.804959]\n",
      "[Epoch 1061/5000] [Batch 0/1] [D loss: 0.166381] [G loss: 1.470535]\n",
      "[Epoch 1062/5000] [Batch 0/1] [D loss: 0.135944] [G loss: 2.029847]\n",
      "[Epoch 1063/5000] [Batch 0/1] [D loss: 0.116139] [G loss: 1.720624]\n",
      "[Epoch 1064/5000] [Batch 0/1] [D loss: 0.134782] [G loss: 2.458618]\n",
      "[Epoch 1065/5000] [Batch 0/1] [D loss: 0.237874] [G loss: 0.978550]\n",
      "[Epoch 1066/5000] [Batch 0/1] [D loss: 0.259011] [G loss: 2.690918]\n",
      "[Epoch 1067/5000] [Batch 0/1] [D loss: 0.191975] [G loss: 1.264042]\n",
      "[Epoch 1068/5000] [Batch 0/1] [D loss: 0.207073] [G loss: 1.312171]\n",
      "[Epoch 1069/5000] [Batch 0/1] [D loss: 0.229568] [G loss: 1.445271]\n",
      "[Epoch 1070/5000] [Batch 0/1] [D loss: 0.222037] [G loss: 1.194885]\n",
      "[Epoch 1071/5000] [Batch 0/1] [D loss: 0.186332] [G loss: 1.473264]\n",
      "[Epoch 1072/5000] [Batch 0/1] [D loss: 0.171655] [G loss: 1.608442]\n",
      "[Epoch 1073/5000] [Batch 0/1] [D loss: 0.159945] [G loss: 1.490609]\n",
      "[Epoch 1074/5000] [Batch 0/1] [D loss: 0.150602] [G loss: 1.695056]\n",
      "[Epoch 1075/5000] [Batch 0/1] [D loss: 0.142258] [G loss: 1.680682]\n",
      "[Epoch 1076/5000] [Batch 0/1] [D loss: 0.137110] [G loss: 1.653090]\n",
      "[Epoch 1077/5000] [Batch 0/1] [D loss: 0.137623] [G loss: 1.840491]\n",
      "[Epoch 1078/5000] [Batch 0/1] [D loss: 0.147769] [G loss: 1.486005]\n",
      "[Epoch 1079/5000] [Batch 0/1] [D loss: 0.169323] [G loss: 2.097160]\n",
      "[Epoch 1080/5000] [Batch 0/1] [D loss: 0.227317] [G loss: 1.030554]\n",
      "[Epoch 1081/5000] [Batch 0/1] [D loss: 0.279608] [G loss: 2.551545]\n",
      "[Epoch 1082/5000] [Batch 0/1] [D loss: 0.191542] [G loss: 1.395158]\n",
      "[Epoch 1083/5000] [Batch 0/1] [D loss: 0.225182] [G loss: 1.117312]\n",
      "[Epoch 1084/5000] [Batch 0/1] [D loss: 0.251755] [G loss: 2.107262]\n",
      "[Epoch 1085/5000] [Batch 0/1] [D loss: 0.200942] [G loss: 1.393486]\n",
      "[Epoch 1086/5000] [Batch 0/1] [D loss: 0.167307] [G loss: 1.469314]\n",
      "[Epoch 1087/5000] [Batch 0/1] [D loss: 0.156518] [G loss: 2.189759]\n",
      "[Epoch 1088/5000] [Batch 0/1] [D loss: 0.137220] [G loss: 1.591378]\n",
      "[Epoch 1089/5000] [Batch 0/1] [D loss: 0.146665] [G loss: 2.020124]\n",
      "[Epoch 1090/5000] [Batch 0/1] [D loss: 0.187179] [G loss: 1.258514]\n",
      "[Epoch 1091/5000] [Batch 0/1] [D loss: 0.273710] [G loss: 2.400249]\n",
      "[Epoch 1092/5000] [Batch 0/1] [D loss: 0.258433] [G loss: 0.997668]\n",
      "[Epoch 1093/5000] [Batch 0/1] [D loss: 0.238184] [G loss: 1.787996]\n",
      "[Epoch 1094/5000] [Batch 0/1] [D loss: 0.182264] [G loss: 1.477265]\n",
      "[Epoch 1095/5000] [Batch 0/1] [D loss: 0.142154] [G loss: 1.662790]\n",
      "[Epoch 1096/5000] [Batch 0/1] [D loss: 0.119899] [G loss: 2.124417]\n",
      "[Epoch 1097/5000] [Batch 0/1] [D loss: 0.112631] [G loss: 1.741730]\n",
      "[Epoch 1098/5000] [Batch 0/1] [D loss: 0.115793] [G loss: 2.254874]\n",
      "[Epoch 1099/5000] [Batch 0/1] [D loss: 0.145491] [G loss: 1.425933]\n",
      "[Epoch 1100/5000] [Batch 0/1] [D loss: 0.217563] [G loss: 2.641372]\n",
      "[Epoch 1101/5000] [Batch 0/1] [D loss: 0.255039] [G loss: 0.932205]\n",
      "[Epoch 1102/5000] [Batch 0/1] [D loss: 0.269989] [G loss: 2.361680]\n",
      "[Epoch 1103/5000] [Batch 0/1] [D loss: 0.227778] [G loss: 1.392296]\n",
      "[Epoch 1104/5000] [Batch 0/1] [D loss: 0.262308] [G loss: 0.986692]\n",
      "[Epoch 1105/5000] [Batch 0/1] [D loss: 0.225978] [G loss: 1.672740]\n",
      "[Epoch 1106/5000] [Batch 0/1] [D loss: 0.188445] [G loss: 1.777238]\n",
      "[Epoch 1107/5000] [Batch 0/1] [D loss: 0.140615] [G loss: 1.694232]\n",
      "[Epoch 1108/5000] [Batch 0/1] [D loss: 0.117110] [G loss: 2.064404]\n",
      "[Epoch 1109/5000] [Batch 0/1] [D loss: 0.109452] [G loss: 1.845544]\n",
      "[Epoch 1110/5000] [Batch 0/1] [D loss: 0.112591] [G loss: 2.029491]\n",
      "[Epoch 1111/5000] [Batch 0/1] [D loss: 0.132202] [G loss: 1.606420]\n",
      "[Epoch 1112/5000] [Batch 0/1] [D loss: 0.179993] [G loss: 2.106917]\n",
      "[Epoch 1113/5000] [Batch 0/1] [D loss: 0.283078] [G loss: 0.852260]\n",
      "[Epoch 1114/5000] [Batch 0/1] [D loss: 0.306737] [G loss: 2.343083]\n",
      "[Epoch 1115/5000] [Batch 0/1] [D loss: 0.224013] [G loss: 1.463178]\n",
      "[Epoch 1116/5000] [Batch 0/1] [D loss: 0.244680] [G loss: 1.009493]\n",
      "[Epoch 1117/5000] [Batch 0/1] [D loss: 0.187821] [G loss: 1.864915]\n",
      "[Epoch 1118/5000] [Batch 0/1] [D loss: 0.147502] [G loss: 1.936418]\n",
      "[Epoch 1119/5000] [Batch 0/1] [D loss: 0.123293] [G loss: 1.680380]\n",
      "[Epoch 1120/5000] [Batch 0/1] [D loss: 0.114385] [G loss: 2.104110]\n",
      "[Epoch 1121/5000] [Batch 0/1] [D loss: 0.116482] [G loss: 1.840346]\n",
      "[Epoch 1122/5000] [Batch 0/1] [D loss: 0.131088] [G loss: 1.762690]\n",
      "[Epoch 1123/5000] [Batch 0/1] [D loss: 0.153270] [G loss: 1.655272]\n",
      "[Epoch 1124/5000] [Batch 0/1] [D loss: 0.185485] [G loss: 1.516162]\n",
      "[Epoch 1125/5000] [Batch 0/1] [D loss: 0.213243] [G loss: 1.460521]\n",
      "[Epoch 1126/5000] [Batch 0/1] [D loss: 0.223053] [G loss: 1.449306]\n",
      "[Epoch 1127/5000] [Batch 0/1] [D loss: 0.192693] [G loss: 1.646911]\n",
      "[Epoch 1128/5000] [Batch 0/1] [D loss: 0.122833] [G loss: 1.926550]\n",
      "[Epoch 1129/5000] [Batch 0/1] [D loss: 0.117754] [G loss: 2.444054]\n",
      "[Epoch 1130/5000] [Batch 0/1] [D loss: 0.247545] [G loss: 0.946078]\n",
      "[Epoch 1131/5000] [Batch 0/1] [D loss: 0.553619] [G loss: 5.545244]\n",
      "[Epoch 1132/5000] [Batch 0/1] [D loss: 0.305060] [G loss: 2.631401]\n",
      "[Epoch 1133/5000] [Batch 0/1] [D loss: 0.363646] [G loss: 0.666778]\n",
      "[Epoch 1134/5000] [Batch 0/1] [D loss: 0.226017] [G loss: 1.419376]\n",
      "[Epoch 1135/5000] [Batch 0/1] [D loss: 0.233969] [G loss: 1.638044]\n",
      "[Epoch 1136/5000] [Batch 0/1] [D loss: 0.196432] [G loss: 1.347793]\n",
      "[Epoch 1137/5000] [Batch 0/1] [D loss: 0.172746] [G loss: 1.395404]\n",
      "[Epoch 1138/5000] [Batch 0/1] [D loss: 0.145677] [G loss: 1.656013]\n",
      "[Epoch 1139/5000] [Batch 0/1] [D loss: 0.131322] [G loss: 1.762207]\n",
      "[Epoch 1140/5000] [Batch 0/1] [D loss: 0.120062] [G loss: 1.724384]\n",
      "[Epoch 1141/5000] [Batch 0/1] [D loss: 0.115268] [G loss: 1.923970]\n",
      "[Epoch 1142/5000] [Batch 0/1] [D loss: 0.124195] [G loss: 1.676763]\n",
      "[Epoch 1143/5000] [Batch 0/1] [D loss: 0.163498] [G loss: 1.919387]\n",
      "[Epoch 1144/5000] [Batch 0/1] [D loss: 0.317024] [G loss: 0.764257]\n",
      "[Epoch 1145/5000] [Batch 0/1] [D loss: 0.439522] [G loss: 3.068614]\n",
      "[Epoch 1146/5000] [Batch 0/1] [D loss: 0.246643] [G loss: 1.619380]\n",
      "[Epoch 1147/5000] [Batch 0/1] [D loss: 0.234265] [G loss: 1.013509]\n",
      "[Epoch 1148/5000] [Batch 0/1] [D loss: 0.198499] [G loss: 2.679849]\n",
      "[Epoch 1149/5000] [Batch 0/1] [D loss: 0.117689] [G loss: 1.695582]\n",
      "[Epoch 1150/5000] [Batch 0/1] [D loss: 0.112321] [G loss: 2.170309]\n",
      "[Epoch 1151/5000] [Batch 0/1] [D loss: 0.169447] [G loss: 1.270839]\n",
      "[Epoch 1152/5000] [Batch 0/1] [D loss: 0.385917] [G loss: 3.302012]\n",
      "[Epoch 1153/5000] [Batch 0/1] [D loss: 0.310784] [G loss: 0.779981]\n",
      "[Epoch 1154/5000] [Batch 0/1] [D loss: 0.295351] [G loss: 1.964015]\n",
      "[Epoch 1155/5000] [Batch 0/1] [D loss: 0.224721] [G loss: 1.295075]\n",
      "[Epoch 1156/5000] [Batch 0/1] [D loss: 0.231197] [G loss: 1.047810]\n",
      "[Epoch 1157/5000] [Batch 0/1] [D loss: 0.220708] [G loss: 1.760031]\n",
      "[Epoch 1158/5000] [Batch 0/1] [D loss: 0.168586] [G loss: 1.426966]\n",
      "[Epoch 1159/5000] [Batch 0/1] [D loss: 0.144107] [G loss: 1.566368]\n",
      "[Epoch 1160/5000] [Batch 0/1] [D loss: 0.136906] [G loss: 1.972574]\n",
      "[Epoch 1161/5000] [Batch 0/1] [D loss: 0.157473] [G loss: 1.330709]\n",
      "[Epoch 1162/5000] [Batch 0/1] [D loss: 0.177381] [G loss: 2.494867]\n",
      "[Epoch 1163/5000] [Batch 0/1] [D loss: 0.198066] [G loss: 1.125777]\n",
      "[Epoch 1164/5000] [Batch 0/1] [D loss: 0.178447] [G loss: 2.282913]\n",
      "[Epoch 1165/5000] [Batch 0/1] [D loss: 0.156179] [G loss: 1.371430]\n",
      "[Epoch 1166/5000] [Batch 0/1] [D loss: 0.155812] [G loss: 1.806988]\n",
      "[Epoch 1167/5000] [Batch 0/1] [D loss: 0.174026] [G loss: 1.314687]\n",
      "[Epoch 1168/5000] [Batch 0/1] [D loss: 0.202506] [G loss: 1.972852]\n",
      "[Epoch 1169/5000] [Batch 0/1] [D loss: 0.208055] [G loss: 1.111048]\n",
      "[Epoch 1170/5000] [Batch 0/1] [D loss: 0.187413] [G loss: 2.110967]\n",
      "[Epoch 1171/5000] [Batch 0/1] [D loss: 0.144025] [G loss: 1.516974]\n",
      "[Epoch 1172/5000] [Batch 0/1] [D loss: 0.126230] [G loss: 1.850329]\n",
      "[Epoch 1173/5000] [Batch 0/1] [D loss: 0.121415] [G loss: 1.809076]\n",
      "[Epoch 1174/5000] [Batch 0/1] [D loss: 0.122273] [G loss: 1.764133]\n",
      "[Epoch 1175/5000] [Batch 0/1] [D loss: 0.129916] [G loss: 1.787679]\n",
      "[Epoch 1176/5000] [Batch 0/1] [D loss: 0.144844] [G loss: 1.561700]\n",
      "[Epoch 1177/5000] [Batch 0/1] [D loss: 0.172698] [G loss: 1.780857]\n",
      "[Epoch 1178/5000] [Batch 0/1] [D loss: 0.265809] [G loss: 0.895982]\n",
      "[Epoch 1179/5000] [Batch 0/1] [D loss: 0.338346] [G loss: 2.585911]\n",
      "[Epoch 1180/5000] [Batch 0/1] [D loss: 0.186274] [G loss: 1.374687]\n",
      "[Epoch 1181/5000] [Batch 0/1] [D loss: 0.167666] [G loss: 1.360896]\n",
      "[Epoch 1182/5000] [Batch 0/1] [D loss: 0.162895] [G loss: 2.063968]\n",
      "[Epoch 1183/5000] [Batch 0/1] [D loss: 0.134056] [G loss: 1.545800]\n",
      "[Epoch 1184/5000] [Batch 0/1] [D loss: 0.131334] [G loss: 2.126571]\n",
      "[Epoch 1185/5000] [Batch 0/1] [D loss: 0.163379] [G loss: 1.311178]\n",
      "[Epoch 1186/5000] [Batch 0/1] [D loss: 0.221691] [G loss: 2.435553]\n",
      "[Epoch 1187/5000] [Batch 0/1] [D loss: 0.259057] [G loss: 0.924088]\n",
      "[Epoch 1188/5000] [Batch 0/1] [D loss: 0.249921] [G loss: 2.152138]\n",
      "[Epoch 1189/5000] [Batch 0/1] [D loss: 0.196548] [G loss: 1.397626]\n",
      "[Epoch 1190/5000] [Batch 0/1] [D loss: 0.201538] [G loss: 1.241807]\n",
      "[Epoch 1191/5000] [Batch 0/1] [D loss: 0.198808] [G loss: 2.029989]\n",
      "[Epoch 1192/5000] [Batch 0/1] [D loss: 0.148546] [G loss: 1.571167]\n",
      "[Epoch 1193/5000] [Batch 0/1] [D loss: 0.121150] [G loss: 1.895193]\n",
      "[Epoch 1194/5000] [Batch 0/1] [D loss: 0.115195] [G loss: 2.052417]\n",
      "[Epoch 1195/5000] [Batch 0/1] [D loss: 0.132239] [G loss: 1.569742]\n",
      "[Epoch 1196/5000] [Batch 0/1] [D loss: 0.176112] [G loss: 2.276103]\n",
      "[Epoch 1197/5000] [Batch 0/1] [D loss: 0.265574] [G loss: 0.900268]\n",
      "[Epoch 1198/5000] [Batch 0/1] [D loss: 0.320263] [G loss: 2.519490]\n",
      "[Epoch 1199/5000] [Batch 0/1] [D loss: 0.215390] [G loss: 1.460471]\n",
      "[Epoch 1200/5000] [Batch 0/1] [D loss: 0.250665] [G loss: 0.965753]\n",
      "[Epoch 1201/5000] [Batch 0/1] [D loss: 0.186900] [G loss: 1.911503]\n",
      "[Epoch 1202/5000] [Batch 0/1] [D loss: 0.156334] [G loss: 1.995529]\n",
      "[Epoch 1203/5000] [Batch 0/1] [D loss: 0.134459] [G loss: 1.589530]\n",
      "[Epoch 1204/5000] [Batch 0/1] [D loss: 0.124351] [G loss: 1.782006]\n",
      "[Epoch 1205/5000] [Batch 0/1] [D loss: 0.126340] [G loss: 1.909817]\n",
      "[Epoch 1206/5000] [Batch 0/1] [D loss: 0.129233] [G loss: 1.714818]\n",
      "[Epoch 1207/5000] [Batch 0/1] [D loss: 0.137257] [G loss: 1.749571]\n",
      "[Epoch 1208/5000] [Batch 0/1] [D loss: 0.150518] [G loss: 1.631432]\n",
      "[Epoch 1209/5000] [Batch 0/1] [D loss: 0.170644] [G loss: 1.541326]\n",
      "[Epoch 1210/5000] [Batch 0/1] [D loss: 0.188793] [G loss: 1.532445]\n",
      "[Epoch 1211/5000] [Batch 0/1] [D loss: 0.213539] [G loss: 1.301802]\n",
      "[Epoch 1212/5000] [Batch 0/1] [D loss: 0.219598] [G loss: 1.637116]\n",
      "[Epoch 1213/5000] [Batch 0/1] [D loss: 0.205412] [G loss: 1.378124]\n",
      "[Epoch 1214/5000] [Batch 0/1] [D loss: 0.175820] [G loss: 1.813958]\n",
      "[Epoch 1215/5000] [Batch 0/1] [D loss: 0.127784] [G loss: 1.815531]\n",
      "[Epoch 1216/5000] [Batch 0/1] [D loss: 0.110466] [G loss: 2.254105]\n",
      "[Epoch 1217/5000] [Batch 0/1] [D loss: 0.113975] [G loss: 1.692084]\n",
      "[Epoch 1218/5000] [Batch 0/1] [D loss: 0.200687] [G loss: 3.128592]\n",
      "[Epoch 1219/5000] [Batch 0/1] [D loss: 0.371530] [G loss: 0.648888]\n",
      "[Epoch 1220/5000] [Batch 0/1] [D loss: 0.437675] [G loss: 4.021383]\n",
      "[Epoch 1221/5000] [Batch 0/1] [D loss: 0.243674] [G loss: 2.199739]\n",
      "[Epoch 1222/5000] [Batch 0/1] [D loss: 0.268819] [G loss: 0.891541]\n",
      "[Epoch 1223/5000] [Batch 0/1] [D loss: 0.169855] [G loss: 1.626451]\n",
      "[Epoch 1224/5000] [Batch 0/1] [D loss: 0.169090] [G loss: 1.914376]\n",
      "[Epoch 1225/5000] [Batch 0/1] [D loss: 0.136569] [G loss: 1.689043]\n",
      "[Epoch 1226/5000] [Batch 0/1] [D loss: 0.124503] [G loss: 1.713541]\n",
      "[Epoch 1227/5000] [Batch 0/1] [D loss: 0.119434] [G loss: 1.962094]\n",
      "[Epoch 1228/5000] [Batch 0/1] [D loss: 0.124356] [G loss: 1.734249]\n",
      "[Epoch 1229/5000] [Batch 0/1] [D loss: 0.144663] [G loss: 1.858128]\n",
      "[Epoch 1230/5000] [Batch 0/1] [D loss: 0.190936] [G loss: 1.250482]\n",
      "[Epoch 1231/5000] [Batch 0/1] [D loss: 0.264287] [G loss: 2.277971]\n",
      "[Epoch 1232/5000] [Batch 0/1] [D loss: 0.230941] [G loss: 1.144781]\n",
      "[Epoch 1233/5000] [Batch 0/1] [D loss: 0.203860] [G loss: 1.499551]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(opt\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Adversarial ground truths\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         valid \u001b[38;5;241m=\u001b[39m Variable(Tensor(imgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m1.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m         fake \u001b[38;5;241m=\u001b[39m Variable(Tensor(imgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m         collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mC:\\ai\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done += 1\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], r\"C:\\Users\\原神\\Downloads\\result1\"+\"\\\\%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a9e259-2334-4c7f-94af-bc7cf7656337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\n",
    "    save_image(gen_imgs.data[-i], r\"C:\\Users\\原神\\Downloads\\result1\"+\"\\\\%d.png\" % (i-1), nrow=1, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc0910-5c90-45c1-bfe7-bfa93dc39cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffmpeg -framerate 8 -i %d.png -crf 0 -pix_fmt yuva420p logo.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06512a9a-ccb0-4cb3-8745-9ce002f8c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9505f687-75a3-49aa-a57d-2d91527948ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39723aa3-c00a-4912-9af2-e08df2099d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.l1(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51480eb2-70fa-41bf-9c58-3b744b8b6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.l1(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99f84523-bc6b-4bf8-a28c-4d83c8ebd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # gen_imgs = generator(z)\n",
    "        # recon_imgs, img_embeddings = discriminator(gen_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa76c08f-57c7-494e-a12f-e4ea9722ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe15ba7-0500-4989-b282-43251286890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ab9971f-2ffd-4f9a-b008-06af8d7f64ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1730a508-1aa3-4c0f-8a63-cd30def5954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pullaway_loss(img_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d92251db-14a4-4ddd-8c0d-d4020568557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixelwise_loss(recon_imgs, gen_imgs.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56b4c162-e046-4987-b68b-ecb54c1ea65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = img_embeddings\n",
    "# norm = torch.sqrt(torch.sum(embeddings ** 2, -1, keepdim=True))\n",
    "# norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "359279f3-99e2-4eb4-a023-05c6db7fdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_emb = embeddings / norm\n",
    "# normalized_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a300c14e-6af6-4d17-9e16-2080be3a8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity = torch.matmul(normalized_emb, normalized_emb.transpose(1, 0))\n",
    "# similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e1b989e-7af1-4657-b169-c6da5e304c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = embeddings.size(0)\n",
    "# batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18f84eb9-289f-4018-b3e3-066e8cc1820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (torch.sum(similarity) - batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b254a56c-5b1d-455a-b2c2-4567f457bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size * (batch_size - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e7f77c1-97e2-43e4-8e5f-9baa621f48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6866a62d-0cf3-4849-a2bb-a69ad5b5bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.init_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c852d7ad-00b7-42c9-8f2b-be973d3266bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.img_size // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e5e4ccb-28ac-4802-8200-b0e857b2da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbe98c40-37e1-4f8f-b6a6-23ce69bef3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = nn.Sequential(nn.Linear(opt.latent_dim, 128 * 32 ** 2))\n",
    "# h.cuda()\n",
    "# h(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "405802dc-3f8b-46d2-9d86-cbd6b3180d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * generator.init_size ** 2))\n",
    "# generator.l1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47906e11-1942-4739-8f8a-6e5b97af7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = Generator()\n",
    "# g.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77f30057-6b12-4434-b8b5-614a239b61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.l1(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9068f014-7d70-463d-a506-f2c779ddc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1d728c8-1306-418c-a337-c2361d556356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c3d6d98-6757-4a5b-8482-e6824765a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.l1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de4a920d-f1a2-4fe4-9104-e7fa4285e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.l1(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6b62aa5-9d96-4cdb-bc09-6e8bf348c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.l1(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71f1b34a-f3e6-43ed-a7a6-d7aabe22bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0b0f27d-379c-4f3b-b6b7-244ba712c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a890d20-24a0-4335-8790-a17cc69020a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3d344ff-dc74-4087-84d5-0b32f1039ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f4a3c05-bbfd-4e0d-a17b-5d97d79aaf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abc41985-d82d-4c92-a4ef-d31e8830c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -6.47948121e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de336ff2-0e94-4533-98fe-3725dedd4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f49e05-ca55-4673-ad07-9ab2b507963e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_image(n_row=opt.n_classes, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8ae25-0e17-4fa1-81d0-3c8598ca2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = r\"C:\\Users\\TEST\\generator_001.pth\"\n",
    "dp = r\"C:\\Users\\TEST\\discriminator_001.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255c631-0aaa-4ba2-8cd9-28e74adeb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), gp)\n",
    "torch.save(discriminator.state_dict(), dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06c9ce-2588-4fba-bb6a-4d83305652bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a random image\n",
    "sample_image(n_row=1, batches_done=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ab4e5-7fb1-450d-a4b8-c62a4b544937",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_state_dict(torch.load(dp, weights_only=True))\n",
    "discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3d1e2-4904-4fe5-af38-c654ab7196b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load(gp, weights_only=True))\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b88aa-a7d0-439a-a849-2fc83a215891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
